{"ast":null,"code":"import { prioritizeTokenScores } from '../components/algorithms.js';\nimport { getFacets } from '../components/facets.js';\nimport { intersectFilteredIDs } from '../components/filters.js';\nimport { getGroups } from '../components/groups.js';\nimport { createError } from '../errors.js';\nimport { getNanosecondsTime, getNested, sortTokenScorePredicate } from '../utils.js';\nconst defaultBM25Params = {\n  k: 1.2,\n  b: 0.75,\n  d: 0.5\n};\nasync function createSearchContext(tokenizer, index, documentsStore, language, params, properties, tokens, docsCount) {\n  // If filters are enabled, we need to get the IDs of the documents that match the filters.\n  // const hasFilters = Object.keys(params.where ?? {}).length > 0;\n  // let whereFiltersIDs: string[] = [];\n  // if (hasFilters) {\n  //   whereFiltersIDs = getWhereFiltersIDs(params.where!, orama);\n  // }\n  // indexMap is an object containing all the indexes considered for the current search,\n  // and an array of doc IDs for each token in all the indices.\n  //\n  // Given the search term \"quick brown fox\" on the \"description\" index,\n  // indexMap will look like this:\n  //\n  // {\n  //   description: {\n  //     quick: [doc1, doc2, doc3],\n  //     brown: [doc2, doc4],\n  //     fox:   [doc2]\n  //   }\n  // }\n  const indexMap = {};\n  // After we create the indexMap, we need to calculate the intersection\n  // between all the postings lists for each token.\n  // Given the example above, docsIntersection will look like this:\n  //\n  // {\n  //   description: [doc2]\n  // }\n  //\n  // as doc2 is the only document present in all the postings lists for the \"description\" index.\n  const docsIntersection = {};\n  for (const prop of properties) {\n    const tokensMap = {};\n    for (const token of tokens) {\n      tokensMap[token] = [];\n    }\n    indexMap[prop] = tokensMap;\n    docsIntersection[prop] = [];\n  }\n  return {\n    timeStart: await getNanosecondsTime(),\n    tokenizer,\n    index,\n    documentsStore,\n    language,\n    params,\n    docsCount,\n    uniqueDocsIDs: {},\n    indexMap,\n    docsIntersection\n  };\n}\nexport async function search(orama, params, language) {\n  params.relevance = Object.assign(params.relevance ?? {}, defaultBM25Params);\n  const shouldCalculateFacets = params.facets && Object.keys(params.facets).length > 0;\n  const {\n    limit = 10,\n    offset = 0,\n    term,\n    properties,\n    threshold = 1,\n    distinctOn\n  } = params;\n  const isPreflight = params.preflight === true;\n  const {\n    index,\n    docs\n  } = orama.data;\n  const tokens = await orama.tokenizer.tokenize(term ?? '', language);\n  // Get searchable string properties\n  let propertiesToSearch = orama.caches['propertiesToSearch'];\n  if (!propertiesToSearch) {\n    const propertiesToSearchWithTypes = await orama.index.getSearchablePropertiesWithTypes(index);\n    propertiesToSearch = await orama.index.getSearchableProperties(index);\n    propertiesToSearch = propertiesToSearch.filter(prop => propertiesToSearchWithTypes[prop].startsWith('string'));\n    orama.caches['propertiesToSearch'] = propertiesToSearch;\n  }\n  if (properties && properties !== '*') {\n    for (const prop of properties) {\n      if (!propertiesToSearch.includes(prop)) {\n        throw createError('UNKNOWN_INDEX', prop, propertiesToSearch.join(', '));\n      }\n    }\n    propertiesToSearch = propertiesToSearch.filter(prop => properties.includes(prop));\n  }\n  // Create the search context and the results\n  const context = await createSearchContext(orama.tokenizer, orama.index, orama.documentsStore, language, params, propertiesToSearch, tokens, await orama.documentsStore.count(docs));\n  // If filters are enabled, we need to get the IDs of the documents that match the filters.\n  const hasFilters = Object.keys(params.where ?? {}).length > 0;\n  let whereFiltersIDs = [];\n  if (hasFilters) {\n    whereFiltersIDs = await orama.index.searchByWhereClause(context, index, params.where);\n  }\n  if (tokens.length) {\n    // Now it's time to loop over all the indices and get the documents IDs for every single term\n    const indexesLength = propertiesToSearch.length;\n    for (let i = 0; i < indexesLength; i++) {\n      var _params_boost;\n      const prop = propertiesToSearch[i];\n      const tokensLength = tokens.length;\n      for (let j = 0; j < tokensLength; j++) {\n        const term = tokens[j];\n        // Lookup\n        const scoreList = await orama.index.search(context, index, prop, term);\n        context.indexMap[prop][term].push(...scoreList);\n      }\n      const docIds = context.indexMap[prop];\n      const vals = Object.values(docIds);\n      context.docsIntersection[prop] = prioritizeTokenScores(vals, (params === null || params === void 0 ? void 0 : (_params_boost = params.boost) === null || _params_boost === void 0 ? void 0 : _params_boost[prop]) ?? 1, threshold);\n      const uniqueDocs = context.docsIntersection[prop];\n      const uniqueDocsLength = uniqueDocs.length;\n      for (let i = 0; i < uniqueDocsLength; i++) {\n        const [id, score] = uniqueDocs[i];\n        const prevScore = context.uniqueDocsIDs[id];\n        if (prevScore) {\n          context.uniqueDocsIDs[id] = prevScore + score + 0.5;\n        } else {\n          context.uniqueDocsIDs[id] = score;\n        }\n      }\n    }\n  } else if (tokens.length === 0 && term) {\n    // This case is hard to handle correctly.\n    // For the time being, if tokenizer returns empty array but the term is not empty,\n    // we returns an empty result set\n    context.uniqueDocsIDs = {};\n  } else {\n    context.uniqueDocsIDs = Object.fromEntries(Object.keys(await orama.documentsStore.getAll(orama.data.docs)).map(k => [k, 0]));\n  }\n  // Get unique doc IDs from uniqueDocsIDs map\n  let uniqueDocsArray = Object.entries(context.uniqueDocsIDs);\n  // If filters are enabled, we need to remove the IDs of the documents that don't match the filters.\n  if (hasFilters) {\n    uniqueDocsArray = intersectFilteredIDs(whereFiltersIDs, uniqueDocsArray);\n  }\n  if (params.sortBy) {\n    if (typeof params.sortBy === 'function') {\n      const ids = uniqueDocsArray.map(_ref => {\n        let [id] = _ref;\n        return id;\n      });\n      const docs = await orama.documentsStore.getMultiple(orama.data.docs, ids);\n      const docsWithIdAndScore = docs.map((d, i) => [uniqueDocsArray[i][0], uniqueDocsArray[i][1], d]);\n      docsWithIdAndScore.sort(params.sortBy);\n      uniqueDocsArray = docsWithIdAndScore.map(_ref2 => {\n        let [id, score] = _ref2;\n        return [id, score];\n      });\n    } else {\n      uniqueDocsArray = await orama.sorter.sortBy(orama.data.sorting, uniqueDocsArray, params.sortBy);\n    }\n  } else {\n    uniqueDocsArray = uniqueDocsArray.sort(sortTokenScorePredicate);\n  }\n  let results;\n  if (!isPreflight && distinctOn) {\n    results = await fetchDocumentsWithDistinct(orama, uniqueDocsArray, offset, limit, distinctOn);\n  } else if (!isPreflight) {\n    results = await fetchDocuments(orama, uniqueDocsArray, offset, limit);\n  }\n  const searchResult = {\n    elapsed: {\n      raw: 0,\n      formatted: ''\n    },\n    // We keep the hits array empty if it's a preflight request.\n    hits: [],\n    count: uniqueDocsArray.length\n  };\n  if (typeof results !== 'undefined') {\n    searchResult.hits = results.filter(Boolean);\n  }\n  if (shouldCalculateFacets) {\n    // Populate facets if needed\n    const facets = await getFacets(orama, uniqueDocsArray, params.facets);\n    searchResult.facets = facets;\n  }\n  if (params.groupBy) {\n    searchResult.groups = await getGroups(orama, uniqueDocsArray, params.groupBy);\n  }\n  searchResult.elapsed = await orama.formatElapsedTime((await getNanosecondsTime()) - context.timeStart);\n  return searchResult;\n}\nasync function fetchDocumentsWithDistinct(orama, uniqueDocsArray, offset, limit, distinctOn) {\n  const docs = orama.data.docs;\n  // Keep track which values we already seen\n  const values = new Map();\n  // We cannot know how many results we will have in the end,\n  // so we need cannot pre-allocate the array.\n  const results = [];\n  const resultIDs = new Set();\n  const uniqueDocsArrayLength = uniqueDocsArray.length;\n  let count = 0;\n  for (let i = 0; i < uniqueDocsArrayLength; i++) {\n    const idAndScore = uniqueDocsArray[i];\n    // If there are no more results, just break the loop\n    if (typeof idAndScore === 'undefined') {\n      continue;\n    }\n    const [id, score] = idAndScore;\n    if (resultIDs.has(id)) {\n      continue;\n    }\n    const doc = await orama.documentsStore.get(docs, id);\n    const value = await getNested(doc, distinctOn);\n    if (typeof value === 'undefined' || values.has(value)) {\n      continue;\n    }\n    values.set(value, true);\n    count++;\n    // We shouldn't consider the document if it's not in the offset range\n    if (count <= offset) {\n      continue;\n    }\n    results.push({\n      id,\n      score,\n      document: doc\n    });\n    resultIDs.add(id);\n    // reached the limit, break the loop\n    if (count >= offset + limit) {\n      break;\n    }\n  }\n  return results;\n}\nasync function fetchDocuments(orama, uniqueDocsArray, offset, limit) {\n  const docs = orama.data.docs;\n  const results = Array.from({\n    length: limit\n  });\n  const resultIDs = new Set();\n  // We already have the list of ALL the document IDs containing the search terms.\n  // We loop over them starting from a positional value \"offset\" and ending at \"offset + limit\"\n  // to provide pagination capabilities to the search.\n  for (let i = offset; i < limit + offset; i++) {\n    const idAndScore = uniqueDocsArray[i];\n    // If there are no more results, just break the loop\n    if (typeof idAndScore === 'undefined') {\n      break;\n    }\n    const [id, score] = idAndScore;\n    if (!resultIDs.has(id)) {\n      // We retrieve the full document only AFTER making sure that we really want it.\n      // We never retrieve the full document preventively.\n      const fullDoc = await orama.documentsStore.get(docs, id);\n      results[i] = {\n        id,\n        score,\n        document: fullDoc\n      };\n      resultIDs.add(id);\n    }\n  }\n  return results;\n}","map":{"version":3,"names":["prioritizeTokenScores","getFacets","intersectFilteredIDs","getGroups","createError","getNanosecondsTime","getNested","sortTokenScorePredicate","defaultBM25Params","k","b","d","createSearchContext","tokenizer","index","documentsStore","language","params","properties","tokens","docsCount","indexMap","docsIntersection","prop","tokensMap","token","timeStart","uniqueDocsIDs","search","orama","relevance","Object","assign","shouldCalculateFacets","facets","keys","length","limit","offset","term","threshold","distinctOn","isPreflight","preflight","docs","data","tokenize","propertiesToSearch","caches","propertiesToSearchWithTypes","getSearchablePropertiesWithTypes","getSearchableProperties","filter","startsWith","includes","join","context","count","hasFilters","where","whereFiltersIDs","searchByWhereClause","indexesLength","i","_params_boost","tokensLength","j","scoreList","push","docIds","vals","values","boost","uniqueDocs","uniqueDocsLength","id","score","prevScore","fromEntries","getAll","map","uniqueDocsArray","entries","sortBy","ids","_ref","getMultiple","docsWithIdAndScore","sort","_ref2","sorter","sorting","results","fetchDocumentsWithDistinct","fetchDocuments","searchResult","elapsed","raw","formatted","hits","Boolean","groupBy","groups","formatElapsedTime","Map","resultIDs","Set","uniqueDocsArrayLength","idAndScore","has","doc","get","value","set","document","add","Array","from","fullDoc"],"sources":["/home/krug/Coding/JavaScript/Websites/Personal/personal/node_modules/.pnpm/@orama+orama@1.0.3/node_modules/@orama/orama/src/methods/search.ts"],"sourcesContent":["import { prioritizeTokenScores } from '../components/algorithms.js'\nimport { getFacets } from '../components/facets.js'\nimport { intersectFilteredIDs } from '../components/filters.js'\nimport { getGroups } from '../components/groups.js'\nimport { createError } from '../errors.js'\nimport {\n  BM25Params,\n  IndexMap,\n  Orama,\n  Result,\n  Results,\n  SearchContext,\n  SearchParams,\n  TokenMap,\n  ElapsedTime,\n  IIndex,\n  Tokenizer,\n  IDocumentsStore,\n  CustomSorterFunctionItem,\n  OpaqueIndex,\n  OpaqueDocumentStore,\n  SearchableValue,\n} from '../types.js'\nimport { getNanosecondsTime, getNested, sortTokenScorePredicate } from '../utils.js'\n\nconst defaultBM25Params: BM25Params = {\n  k: 1.2,\n  b: 0.75,\n  d: 0.5,\n}\n\nasync function createSearchContext<I extends OpaqueIndex, D extends OpaqueDocumentStore, AggValue>(\n  tokenizer: Tokenizer,\n  index: IIndex<I>,\n  documentsStore: IDocumentsStore<D>,\n  language: string | undefined,\n  params: SearchParams<AggValue>,\n  properties: string[],\n  tokens: string[],\n  docsCount: number,\n): Promise<SearchContext<I, D, AggValue>> {\n  // If filters are enabled, we need to get the IDs of the documents that match the filters.\n  // const hasFilters = Object.keys(params.where ?? {}).length > 0;\n  // let whereFiltersIDs: string[] = [];\n\n  // if (hasFilters) {\n  //   whereFiltersIDs = getWhereFiltersIDs(params.where!, orama);\n  // }\n\n  // indexMap is an object containing all the indexes considered for the current search,\n  // and an array of doc IDs for each token in all the indices.\n  //\n  // Given the search term \"quick brown fox\" on the \"description\" index,\n  // indexMap will look like this:\n  //\n  // {\n  //   description: {\n  //     quick: [doc1, doc2, doc3],\n  //     brown: [doc2, doc4],\n  //     fox:   [doc2]\n  //   }\n  // }\n  const indexMap: IndexMap = {}\n\n  // After we create the indexMap, we need to calculate the intersection\n  // between all the postings lists for each token.\n  // Given the example above, docsIntersection will look like this:\n  //\n  // {\n  //   description: [doc2]\n  // }\n  //\n  // as doc2 is the only document present in all the postings lists for the \"description\" index.\n  const docsIntersection: TokenMap = {}\n\n  for (const prop of properties) {\n    const tokensMap: TokenMap = {}\n    for (const token of tokens) {\n      tokensMap[token] = []\n    }\n    indexMap[prop] = tokensMap\n    docsIntersection[prop] = []\n  }\n\n  return {\n    timeStart: await getNanosecondsTime(),\n    tokenizer,\n    index,\n    documentsStore,\n    language,\n    params,\n    docsCount,\n    uniqueDocsIDs: {},\n    indexMap,\n    docsIntersection,\n  }\n}\n\nexport async function search<AggValue = Result[]>(orama: Orama, params: SearchParams<AggValue>, language?: string): Promise<Results<AggValue>> {\n  params.relevance = Object.assign(params.relevance ?? {}, defaultBM25Params)\n\n  const shouldCalculateFacets = params.facets && Object.keys(params.facets).length > 0\n  const { limit = 10, offset = 0, term, properties, threshold = 1, distinctOn } = params\n  const isPreflight = params.preflight === true\n\n  const { index, docs } = orama.data\n  const tokens = await orama.tokenizer.tokenize(term ?? '', language)\n\n  // Get searchable string properties\n  let propertiesToSearch = orama.caches['propertiesToSearch'] as string[]\n  if (!propertiesToSearch) {\n    const propertiesToSearchWithTypes = await orama.index.getSearchablePropertiesWithTypes(index)\n\n    propertiesToSearch = await orama.index.getSearchableProperties(index)\n    propertiesToSearch = propertiesToSearch.filter((prop: string) =>\n      propertiesToSearchWithTypes[prop].startsWith('string'),\n    )\n\n    orama.caches['propertiesToSearch'] = propertiesToSearch\n  }\n\n  if (properties && properties !== '*') {\n    for (const prop of properties) {\n      if (!propertiesToSearch.includes(prop)) {\n        throw createError('UNKNOWN_INDEX', prop, propertiesToSearch.join(', '))\n      }\n    }\n\n    propertiesToSearch = propertiesToSearch.filter((prop: string) => properties.includes(prop))\n  }\n\n  // Create the search context and the results\n  const context = await createSearchContext(\n    orama.tokenizer,\n    orama.index,\n    orama.documentsStore,\n    language,\n    params,\n    propertiesToSearch,\n    tokens,\n    await orama.documentsStore.count(docs),\n  )\n\n  // If filters are enabled, we need to get the IDs of the documents that match the filters.\n  const hasFilters = Object.keys(params.where ?? {}).length > 0\n  let whereFiltersIDs: string[] = []\n\n  if (hasFilters) {\n    whereFiltersIDs = await orama.index.searchByWhereClause(context, index, params.where!)\n  }\n\n  if (tokens.length) {\n    // Now it's time to loop over all the indices and get the documents IDs for every single term\n    const indexesLength = propertiesToSearch.length\n    for (let i = 0; i < indexesLength; i++) {\n      const prop = propertiesToSearch[i]\n\n      const tokensLength = tokens.length\n      for (let j = 0; j < tokensLength; j++) {\n        const term = tokens[j]\n\n        // Lookup\n        const scoreList = await orama.index.search(context, index, prop, term)\n\n        context.indexMap[prop][term].push(...scoreList)\n      }\n\n      const docIds = context.indexMap[prop]\n      const vals = Object.values(docIds)\n      context.docsIntersection[prop] = prioritizeTokenScores(vals, params?.boost?.[prop] ?? 1, threshold)\n      const uniqueDocs = context.docsIntersection[prop]\n\n      const uniqueDocsLength = uniqueDocs.length\n      for (let i = 0; i < uniqueDocsLength; i++) {\n        const [id, score] = uniqueDocs[i]\n\n        const prevScore = context.uniqueDocsIDs[id]\n        if (prevScore) {\n          context.uniqueDocsIDs[id] = prevScore + score + 0.5\n        } else {\n          context.uniqueDocsIDs[id] = score\n        }\n      }\n    }\n  } else if (tokens.length === 0 && term) {\n    // This case is hard to handle correctly.\n    // For the time being, if tokenizer returns empty array but the term is not empty,\n    // we returns an empty result set\n    context.uniqueDocsIDs = {}\n  } else {\n    context.uniqueDocsIDs = Object.fromEntries(\n      Object.keys(await orama.documentsStore.getAll(orama.data.docs)).map(k => [k, 0]),\n    )\n  }\n\n  // Get unique doc IDs from uniqueDocsIDs map\n  let uniqueDocsArray = Object.entries(context.uniqueDocsIDs)\n\n  // If filters are enabled, we need to remove the IDs of the documents that don't match the filters.\n  if (hasFilters) {\n    uniqueDocsArray = intersectFilteredIDs(whereFiltersIDs, uniqueDocsArray)\n  }\n\n  if (params.sortBy) {\n    if (typeof params.sortBy === 'function') {\n      const ids: string[] = uniqueDocsArray.map(([id]) => id)\n      const docs = await orama.documentsStore.getMultiple(orama.data.docs, ids)\n      const docsWithIdAndScore: CustomSorterFunctionItem[] = docs.map((d, i) => [\n        uniqueDocsArray[i][0],\n        uniqueDocsArray[i][1],\n        d!,\n      ])\n      docsWithIdAndScore.sort(params.sortBy)\n      uniqueDocsArray = docsWithIdAndScore.map(([id, score]) => [id, score])\n    } else {\n      uniqueDocsArray = await orama.sorter.sortBy(orama.data.sorting, uniqueDocsArray, params.sortBy)\n    }\n  } else {\n    uniqueDocsArray = uniqueDocsArray.sort(sortTokenScorePredicate)\n  }\n\n  let results\n  if (!isPreflight && distinctOn) {\n    results = await fetchDocumentsWithDistinct(orama, uniqueDocsArray, offset, limit, distinctOn)\n  } else if (!isPreflight) {\n    results = await fetchDocuments(orama, uniqueDocsArray, offset, limit)\n  }\n\n  const searchResult: Results<AggValue> = {\n    elapsed: {\n      raw: 0,\n      formatted: '',\n    },\n    // We keep the hits array empty if it's a preflight request.\n    hits: [],\n    count: uniqueDocsArray.length,\n  }\n\n  if (typeof results !== 'undefined') {\n    searchResult.hits = results.filter(Boolean)\n  }\n\n  if (shouldCalculateFacets) {\n    // Populate facets if needed\n    const facets = await getFacets(orama, uniqueDocsArray, params.facets!)\n    searchResult.facets = facets\n  }\n\n  if (params.groupBy) {\n    searchResult.groups = await getGroups(orama, uniqueDocsArray, params.groupBy)\n  }\n\n  searchResult.elapsed = (await orama.formatElapsedTime(\n    (await getNanosecondsTime()) - context.timeStart,\n  )) as ElapsedTime\n\n  return searchResult\n}\n\nasync function fetchDocumentsWithDistinct(\n  orama: Orama,\n  uniqueDocsArray: [string, number][],\n  offset: number,\n  limit: number,\n  distinctOn: string,\n): Promise<Result[]> {\n  const docs = orama.data.docs\n\n  // Keep track which values we already seen\n  const values = new Map<SearchableValue, true>()\n\n  // We cannot know how many results we will have in the end,\n  // so we need cannot pre-allocate the array.\n  const results: Result[] = []\n\n  const resultIDs: Set<string> = new Set()\n  const uniqueDocsArrayLength = uniqueDocsArray.length\n  let count = 0\n  for (let i = 0; i < uniqueDocsArrayLength; i++) {\n    const idAndScore = uniqueDocsArray[i]\n\n    // If there are no more results, just break the loop\n    if (typeof idAndScore === 'undefined') {\n      continue\n    }\n\n    const [id, score] = idAndScore\n\n    if (resultIDs.has(id)) {\n      continue\n    }\n\n    const doc = await orama.documentsStore.get(docs, id)\n    const value = await getNested(doc as object, distinctOn)\n    if (typeof value === 'undefined' || values.has(value)) {\n      continue\n    }\n    values.set(value, true)\n\n    count++\n    // We shouldn't consider the document if it's not in the offset range\n    if (count <= offset) {\n      continue\n    }\n\n    results.push({ id, score, document: doc! })\n    resultIDs.add(id)\n\n    // reached the limit, break the loop\n    if (count >= offset + limit) {\n      break\n    }\n  }\n\n  return results\n}\n\nasync function fetchDocuments(\n  orama: Orama,\n  uniqueDocsArray: [string, number][],\n  offset: number,\n  limit: number,\n): Promise<Result[]> {\n  const docs = orama.data.docs\n\n  const results: Result[] = Array.from({\n    length: limit,\n  })\n\n  const resultIDs: Set<string> = new Set()\n\n  // We already have the list of ALL the document IDs containing the search terms.\n  // We loop over them starting from a positional value \"offset\" and ending at \"offset + limit\"\n  // to provide pagination capabilities to the search.\n  for (let i = offset; i < limit + offset; i++) {\n    const idAndScore = uniqueDocsArray[i]\n\n    // If there are no more results, just break the loop\n    if (typeof idAndScore === 'undefined') {\n      break\n    }\n\n    const [id, score] = idAndScore\n\n    if (!resultIDs.has(id)) {\n      // We retrieve the full document only AFTER making sure that we really want it.\n      // We never retrieve the full document preventively.\n      const fullDoc = await orama.documentsStore.get(docs, id)\n      results[i] = { id, score, document: fullDoc! }\n      resultIDs.add(id)\n    }\n  }\n  return results\n}"],"mappings":"AAAA,SAASA,qBAAqB,QAAQ;AACtC,SAASC,SAAS,QAAQ;AAC1B,SAASC,oBAAoB,QAAQ;AACrC,SAASC,SAAS,QAAQ;AAC1B,SAASC,WAAW,QAAQ;AAmB5B,SAASC,kBAAkB,EAAEC,SAAS,EAAEC,uBAAuB,QAAQ;AAEvE,MAAMC,iBAAA,GAAgC;EACpCC,CAAA,EAAG;EACHC,CAAA,EAAG;EACHC,CAAA,EAAG;AACL;AAEA,eAAeC,oBACbC,SAAoB,EACpBC,KAAgB,EAChBC,cAAkC,EAClCC,QAA4B,EAC5BC,MAA8B,EAC9BC,UAAoB,EACpBC,MAAgB,EAChBC,SAAiB,EACuB;EACxC;EACA;EACA;EAEA;EACA;EACA;EAEA;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EACA,MAAMC,QAAA,GAAqB,CAAC;EAE5B;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EACA,MAAMC,gBAAA,GAA6B,CAAC;EAEpC,KAAK,MAAMC,IAAA,IAAQL,UAAA,EAAY;IAC7B,MAAMM,SAAA,GAAsB,CAAC;IAC7B,KAAK,MAAMC,KAAA,IAASN,MAAA,EAAQ;MAC1BK,SAAS,CAACC,KAAA,CAAM,GAAG,EAAE;IACvB;IACAJ,QAAQ,CAACE,IAAA,CAAK,GAAGC,SAAA;IACjBF,gBAAgB,CAACC,IAAA,CAAK,GAAG,EAAE;EAC7B;EAEA,OAAO;IACLG,SAAA,EAAW,MAAMrB,kBAAA;IACjBQ,SAAA;IACAC,KAAA;IACAC,cAAA;IACAC,QAAA;IACAC,MAAA;IACAG,SAAA;IACAO,aAAA,EAAe,CAAC;IAChBN,QAAA;IACAC;EACF;AACF;AAEA,OAAO,eAAeM,OAA4BC,KAAY,EAAEZ,MAA8B,EAAED,QAAiB,EAA8B;EAC7IC,MAAA,CAAOa,SAAS,GAAGC,MAAA,CAAOC,MAAM,CAACf,MAAA,CAAOa,SAAS,IAAI,CAAC,GAAGtB,iBAAA;EAEzD,MAAMyB,qBAAA,GAAwBhB,MAAA,CAAOiB,MAAM,IAAIH,MAAA,CAAOI,IAAI,CAAClB,MAAA,CAAOiB,MAAM,EAAEE,MAAM,GAAG;EACnF,MAAM;IAAEC,KAAA,GAAQ;IAAIC,MAAA,GAAS;IAAGC,IAAA;IAAMrB,UAAA;IAAYsB,SAAA,GAAY;IAAGC;EAAU,CAAE,GAAGxB,MAAA;EAChF,MAAMyB,WAAA,GAAczB,MAAA,CAAO0B,SAAS,KAAK,IAAI;EAE7C,MAAM;IAAE7B,KAAA;IAAO8B;EAAI,CAAE,GAAGf,KAAA,CAAMgB,IAAI;EAClC,MAAM1B,MAAA,GAAS,MAAMU,KAAA,CAAMhB,SAAS,CAACiC,QAAQ,CAACP,IAAA,IAAQ,IAAIvB,QAAA;EAE1D;EACA,IAAI+B,kBAAA,GAAqBlB,KAAA,CAAMmB,MAAM,CAAC,qBAAqB;EAC3D,IAAI,CAACD,kBAAA,EAAoB;IACvB,MAAME,2BAAA,GAA8B,MAAMpB,KAAA,CAAMf,KAAK,CAACoC,gCAAgC,CAACpC,KAAA;IAEvFiC,kBAAA,GAAqB,MAAMlB,KAAA,CAAMf,KAAK,CAACqC,uBAAuB,CAACrC,KAAA;IAC/DiC,kBAAA,GAAqBA,kBAAA,CAAmBK,MAAM,CAAE7B,IAAA,IAC9C0B,2BAA2B,CAAC1B,IAAA,CAAK,CAAC8B,UAAU,CAAC;IAG/CxB,KAAA,CAAMmB,MAAM,CAAC,qBAAqB,GAAGD,kBAAA;EACvC;EAEA,IAAI7B,UAAA,IAAcA,UAAA,KAAe,KAAK;IACpC,KAAK,MAAMK,IAAA,IAAQL,UAAA,EAAY;MAC7B,IAAI,CAAC6B,kBAAA,CAAmBO,QAAQ,CAAC/B,IAAA,GAAO;QACtC,MAAMnB,WAAA,CAAY,iBAAiBmB,IAAA,EAAMwB,kBAAA,CAAmBQ,IAAI,CAAC;MACnE;IACF;IAEAR,kBAAA,GAAqBA,kBAAA,CAAmBK,MAAM,CAAE7B,IAAA,IAAiBL,UAAA,CAAWoC,QAAQ,CAAC/B,IAAA;EACvF;EAEA;EACA,MAAMiC,OAAA,GAAU,MAAM5C,mBAAA,CACpBiB,KAAA,CAAMhB,SAAS,EACfgB,KAAA,CAAMf,KAAK,EACXe,KAAA,CAAMd,cAAc,EACpBC,QAAA,EACAC,MAAA,EACA8B,kBAAA,EACA5B,MAAA,EACA,MAAMU,KAAA,CAAMd,cAAc,CAAC0C,KAAK,CAACb,IAAA;EAGnC;EACA,MAAMc,UAAA,GAAa3B,MAAA,CAAOI,IAAI,CAAClB,MAAA,CAAO0C,KAAK,IAAI,CAAC,GAAGvB,MAAM,GAAG;EAC5D,IAAIwB,eAAA,GAA4B,EAAE;EAElC,IAAIF,UAAA,EAAY;IACdE,eAAA,GAAkB,MAAM/B,KAAA,CAAMf,KAAK,CAAC+C,mBAAmB,CAACL,OAAA,EAAS1C,KAAA,EAAOG,MAAA,CAAO0C,KAAK;EACtF;EAEA,IAAIxC,MAAA,CAAOiB,MAAM,EAAE;IACjB;IACA,MAAM0B,aAAA,GAAgBf,kBAAA,CAAmBX,MAAM;IAC/C,KAAK,IAAI2B,CAAA,GAAI,GAAGA,CAAA,GAAID,aAAA,EAAeC,CAAA,IAAK;UAeuBC,aAAA;MAd7D,MAAMzC,IAAA,GAAOwB,kBAAkB,CAACgB,CAAA,CAAE;MAElC,MAAME,YAAA,GAAe9C,MAAA,CAAOiB,MAAM;MAClC,KAAK,IAAI8B,CAAA,GAAI,GAAGA,CAAA,GAAID,YAAA,EAAcC,CAAA,IAAK;QACrC,MAAM3B,IAAA,GAAOpB,MAAM,CAAC+C,CAAA,CAAE;QAEtB;QACA,MAAMC,SAAA,GAAY,MAAMtC,KAAA,CAAMf,KAAK,CAACc,MAAM,CAAC4B,OAAA,EAAS1C,KAAA,EAAOS,IAAA,EAAMgB,IAAA;QAEjEiB,OAAA,CAAQnC,QAAQ,CAACE,IAAA,CAAK,CAACgB,IAAA,CAAK,CAAC6B,IAAI,IAAID,SAAA;MACvC;MAEA,MAAME,MAAA,GAASb,OAAA,CAAQnC,QAAQ,CAACE,IAAA,CAAK;MACrC,MAAM+C,IAAA,GAAOvC,MAAA,CAAOwC,MAAM,CAACF,MAAA;MAC3Bb,OAAA,CAAQlC,gBAAgB,CAACC,IAAA,CAAK,GAAGvB,qBAAA,CAAsBsE,IAAA,EAAM,CAAArD,MAAA,aAAAA,MAAA,wBAAA+C,aAAA,GAAA/C,MAAA,CAAQuD,KAAK,cAAbR,aAAA,uBAAAA,aAAe,CAACzC,IAAA,CAAK,KAAI,GAAGiB,SAAA;MACzF,MAAMiC,UAAA,GAAajB,OAAA,CAAQlC,gBAAgB,CAACC,IAAA,CAAK;MAEjD,MAAMmD,gBAAA,GAAmBD,UAAA,CAAWrC,MAAM;MAC1C,KAAK,IAAI2B,CAAA,GAAI,GAAGA,CAAA,GAAIW,gBAAA,EAAkBX,CAAA,IAAK;QACzC,MAAM,CAACY,EAAA,EAAIC,KAAA,CAAM,GAAGH,UAAU,CAACV,CAAA,CAAE;QAEjC,MAAMc,SAAA,GAAYrB,OAAA,CAAQ7B,aAAa,CAACgD,EAAA,CAAG;QAC3C,IAAIE,SAAA,EAAW;UACbrB,OAAA,CAAQ7B,aAAa,CAACgD,EAAA,CAAG,GAAGE,SAAA,GAAYD,KAAA,GAAQ;QAClD,OAAO;UACLpB,OAAA,CAAQ7B,aAAa,CAACgD,EAAA,CAAG,GAAGC,KAAA;QAC9B;MACF;IACF;EACF,OAAO,IAAIzD,MAAA,CAAOiB,MAAM,KAAK,KAAKG,IAAA,EAAM;IACtC;IACA;IACA;IACAiB,OAAA,CAAQ7B,aAAa,GAAG,CAAC;EAC3B,OAAO;IACL6B,OAAA,CAAQ7B,aAAa,GAAGI,MAAA,CAAO+C,WAAW,CACxC/C,MAAA,CAAOI,IAAI,CAAC,MAAMN,KAAA,CAAMd,cAAc,CAACgE,MAAM,CAAClD,KAAA,CAAMgB,IAAI,CAACD,IAAI,GAAGoC,GAAG,CAACvE,CAAA,IAAK,CAACA,CAAA,EAAG,EAAE;EAEnF;EAEA;EACA,IAAIwE,eAAA,GAAkBlD,MAAA,CAAOmD,OAAO,CAAC1B,OAAA,CAAQ7B,aAAa;EAE1D;EACA,IAAI+B,UAAA,EAAY;IACduB,eAAA,GAAkB/E,oBAAA,CAAqB0D,eAAA,EAAiBqB,eAAA;EAC1D;EAEA,IAAIhE,MAAA,CAAOkE,MAAM,EAAE;IACjB,IAAI,OAAOlE,MAAA,CAAOkE,MAAM,KAAK,YAAY;MACvC,MAAMC,GAAA,GAAgBH,eAAA,CAAgBD,GAAG,CAACK,IAAA;QAAA,IAAC,CAACV,EAAA,CAAG,GAAAU,IAAA;QAAA,OAAKV,EAAA;MAAA;MACpD,MAAM/B,IAAA,GAAO,MAAMf,KAAA,CAAMd,cAAc,CAACuE,WAAW,CAACzD,KAAA,CAAMgB,IAAI,CAACD,IAAI,EAAEwC,GAAA;MACrE,MAAMG,kBAAA,GAAiD3C,IAAA,CAAKoC,GAAG,CAAC,CAACrE,CAAA,EAAGoD,CAAA,KAAM,CACxEkB,eAAe,CAAClB,CAAA,CAAE,CAAC,EAAE,EACrBkB,eAAe,CAAClB,CAAA,CAAE,CAAC,EAAE,EACrBpD,CAAA,CACD;MACD4E,kBAAA,CAAmBC,IAAI,CAACvE,MAAA,CAAOkE,MAAM;MACrCF,eAAA,GAAkBM,kBAAA,CAAmBP,GAAG,CAACS,KAAA;QAAA,IAAC,CAACd,EAAA,EAAIC,KAAA,CAAM,GAAAa,KAAA;QAAA,OAAK,CAACd,EAAA,EAAIC,KAAA,CAAM;MAAA;IACvE,OAAO;MACLK,eAAA,GAAkB,MAAMpD,KAAA,CAAM6D,MAAM,CAACP,MAAM,CAACtD,KAAA,CAAMgB,IAAI,CAAC8C,OAAO,EAAEV,eAAA,EAAiBhE,MAAA,CAAOkE,MAAM;IAChG;EACF,OAAO;IACLF,eAAA,GAAkBA,eAAA,CAAgBO,IAAI,CAACjF,uBAAA;EACzC;EAEA,IAAIqF,OAAA;EACJ,IAAI,CAAClD,WAAA,IAAeD,UAAA,EAAY;IAC9BmD,OAAA,GAAU,MAAMC,0BAAA,CAA2BhE,KAAA,EAAOoD,eAAA,EAAiB3C,MAAA,EAAQD,KAAA,EAAOI,UAAA;EACpF,OAAO,IAAI,CAACC,WAAA,EAAa;IACvBkD,OAAA,GAAU,MAAME,cAAA,CAAejE,KAAA,EAAOoD,eAAA,EAAiB3C,MAAA,EAAQD,KAAA;EACjE;EAEA,MAAM0D,YAAA,GAAkC;IACtCC,OAAA,EAAS;MACPC,GAAA,EAAK;MACLC,SAAA,EAAW;IACb;IACA;IACAC,IAAA,EAAM,EAAE;IACR1C,KAAA,EAAOwB,eAAA,CAAgB7C;EACzB;EAEA,IAAI,OAAOwD,OAAA,KAAY,aAAa;IAClCG,YAAA,CAAaI,IAAI,GAAGP,OAAA,CAAQxC,MAAM,CAACgD,OAAA;EACrC;EAEA,IAAInE,qBAAA,EAAuB;IACzB;IACA,MAAMC,MAAA,GAAS,MAAMjC,SAAA,CAAU4B,KAAA,EAAOoD,eAAA,EAAiBhE,MAAA,CAAOiB,MAAM;IACpE6D,YAAA,CAAa7D,MAAM,GAAGA,MAAA;EACxB;EAEA,IAAIjB,MAAA,CAAOoF,OAAO,EAAE;IAClBN,YAAA,CAAaO,MAAM,GAAG,MAAMnG,SAAA,CAAU0B,KAAA,EAAOoD,eAAA,EAAiBhE,MAAA,CAAOoF,OAAO;EAC9E;EAEAN,YAAA,CAAaC,OAAO,GAAI,MAAMnE,KAAA,CAAM0E,iBAAiB,CACnD,OAAOlG,kBAAA,MAAwBmD,OAAA,CAAQ9B,SAAS;EAGlD,OAAOqE,YAAA;AACT;AAEA,eAAeF,2BACbhE,KAAY,EACZoD,eAAmC,EACnC3C,MAAc,EACdD,KAAa,EACbI,UAAkB,EACC;EACnB,MAAMG,IAAA,GAAOf,KAAA,CAAMgB,IAAI,CAACD,IAAI;EAE5B;EACA,MAAM2B,MAAA,GAAS,IAAIiC,GAAA;EAEnB;EACA;EACA,MAAMZ,OAAA,GAAoB,EAAE;EAE5B,MAAMa,SAAA,GAAyB,IAAIC,GAAA;EACnC,MAAMC,qBAAA,GAAwB1B,eAAA,CAAgB7C,MAAM;EACpD,IAAIqB,KAAA,GAAQ;EACZ,KAAK,IAAIM,CAAA,GAAI,GAAGA,CAAA,GAAI4C,qBAAA,EAAuB5C,CAAA,IAAK;IAC9C,MAAM6C,UAAA,GAAa3B,eAAe,CAAClB,CAAA,CAAE;IAErC;IACA,IAAI,OAAO6C,UAAA,KAAe,aAAa;MACrC;IACF;IAEA,MAAM,CAACjC,EAAA,EAAIC,KAAA,CAAM,GAAGgC,UAAA;IAEpB,IAAIH,SAAA,CAAUI,GAAG,CAAClC,EAAA,GAAK;MACrB;IACF;IAEA,MAAMmC,GAAA,GAAM,MAAMjF,KAAA,CAAMd,cAAc,CAACgG,GAAG,CAACnE,IAAA,EAAM+B,EAAA;IACjD,MAAMqC,KAAA,GAAQ,MAAM1G,SAAA,CAAUwG,GAAA,EAAerE,UAAA;IAC7C,IAAI,OAAOuE,KAAA,KAAU,eAAezC,MAAA,CAAOsC,GAAG,CAACG,KAAA,GAAQ;MACrD;IACF;IACAzC,MAAA,CAAO0C,GAAG,CAACD,KAAA,EAAO,IAAI;IAEtBvD,KAAA;IACA;IACA,IAAIA,KAAA,IAASnB,MAAA,EAAQ;MACnB;IACF;IAEAsD,OAAA,CAAQxB,IAAI,CAAC;MAAEO,EAAA;MAAIC,KAAA;MAAOsC,QAAA,EAAUJ;IAAK;IACzCL,SAAA,CAAUU,GAAG,CAACxC,EAAA;IAEd;IACA,IAAIlB,KAAA,IAASnB,MAAA,GAASD,KAAA,EAAO;MAC3B;IACF;EACF;EAEA,OAAOuD,OAAA;AACT;AAEA,eAAeE,eACbjE,KAAY,EACZoD,eAAmC,EACnC3C,MAAc,EACdD,KAAa,EACM;EACnB,MAAMO,IAAA,GAAOf,KAAA,CAAMgB,IAAI,CAACD,IAAI;EAE5B,MAAMgD,OAAA,GAAoBwB,KAAA,CAAMC,IAAI,CAAC;IACnCjF,MAAA,EAAQC;EACV;EAEA,MAAMoE,SAAA,GAAyB,IAAIC,GAAA;EAEnC;EACA;EACA;EACA,KAAK,IAAI3C,CAAA,GAAIzB,MAAA,EAAQyB,CAAA,GAAI1B,KAAA,GAAQC,MAAA,EAAQyB,CAAA,IAAK;IAC5C,MAAM6C,UAAA,GAAa3B,eAAe,CAAClB,CAAA,CAAE;IAErC;IACA,IAAI,OAAO6C,UAAA,KAAe,aAAa;MACrC;IACF;IAEA,MAAM,CAACjC,EAAA,EAAIC,KAAA,CAAM,GAAGgC,UAAA;IAEpB,IAAI,CAACH,SAAA,CAAUI,GAAG,CAAClC,EAAA,GAAK;MACtB;MACA;MACA,MAAM2C,OAAA,GAAU,MAAMzF,KAAA,CAAMd,cAAc,CAACgG,GAAG,CAACnE,IAAA,EAAM+B,EAAA;MACrDiB,OAAO,CAAC7B,CAAA,CAAE,GAAG;QAAEY,EAAA;QAAIC,KAAA;QAAOsC,QAAA,EAAUI;MAAS;MAC7Cb,SAAA,CAAUU,GAAG,CAACxC,EAAA;IAChB;EACF;EACA,OAAOiB,OAAA;AACT"},"metadata":{},"sourceType":"module","externalDependencies":[]}