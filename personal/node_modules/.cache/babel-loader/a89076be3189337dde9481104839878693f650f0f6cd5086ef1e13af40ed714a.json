{"ast":null,"code":"import { prioritizeTokenScores } from '../components/algorithms.js';\nimport { getFacets } from '../components/facets.js';\nimport { intersectFilteredIDs } from '../components/filters.js';\nimport { getGroups } from '../components/groups.js';\nimport { runAfterSearch } from '../components/hooks.js';\nimport { getDocumentIdFromInternalId, getInternalDocumentId } from '../components/internal-document-id-store.js';\nimport { createError } from '../errors.js';\nimport { getNanosecondsTime, getNested, sortTokenScorePredicate, safeArrayPush } from '../utils.js';\nconst defaultBM25Params = {\n  k: 1.2,\n  b: 0.75,\n  d: 0.5\n};\nasync function createSearchContext(tokenizer, index, documentsStore, language, params, properties, tokens, docsCount, timeStart) {\n  // If filters are enabled, we need to get the IDs of the documents that match the filters.\n  // const hasFilters = Object.keys(params.where ?? {}).length > 0;\n  // let whereFiltersIDs: string[] = [];\n  // if (hasFilters) {\n  //   whereFiltersIDs = getWhereFiltersIDs(params.where!, orama);\n  // }\n  // indexMap is an object containing all the indexes considered for the current search,\n  // and an array of doc IDs for each token in all the indices.\n  //\n  // Given the search term \"quick brown fox\" on the \"description\" index,\n  // indexMap will look like this:\n  //\n  // {\n  //   description: {\n  //     quick: [doc1, doc2, doc3],\n  //     brown: [doc2, doc4],\n  //     fox:   [doc2]\n  //   }\n  // }\n  const indexMap = {};\n  // After we create the indexMap, we need to calculate the intersection\n  // between all the postings lists for each token.\n  // Given the example above, docsIntersection will look like this:\n  //\n  // {\n  //   description: [doc2]\n  // }\n  //\n  // as doc2 is the only document present in all the postings lists for the \"description\" index.\n  const docsIntersection = {};\n  for (const prop of properties) {\n    const tokensMap = {};\n    for (const token of tokens) {\n      tokensMap[token] = [];\n    }\n    indexMap[prop] = tokensMap;\n    docsIntersection[prop] = [];\n  }\n  return {\n    timeStart,\n    tokenizer,\n    index,\n    documentsStore,\n    language,\n    params,\n    docsCount,\n    uniqueDocsIDs: {},\n    indexMap,\n    docsIntersection\n  };\n}\nexport async function search(orama, params, language) {\n  const timeStart = await getNanosecondsTime();\n  params.relevance = Object.assign(params.relevance ?? {}, defaultBM25Params);\n  const shouldCalculateFacets = params.facets && Object.keys(params.facets).length > 0;\n  const {\n    limit = 10,\n    offset = 0,\n    term,\n    properties,\n    threshold = 1,\n    distinctOn\n  } = params;\n  const isPreflight = params.preflight === true;\n  const {\n    index,\n    docs\n  } = orama.data;\n  const tokens = await orama.tokenizer.tokenize(term ?? '', language);\n  // Get searchable string properties\n  let propertiesToSearch = orama.caches['propertiesToSearch'];\n  if (!propertiesToSearch) {\n    const propertiesToSearchWithTypes = await orama.index.getSearchablePropertiesWithTypes(index);\n    propertiesToSearch = await orama.index.getSearchableProperties(index);\n    propertiesToSearch = propertiesToSearch.filter(prop => propertiesToSearchWithTypes[prop].startsWith('string'));\n    orama.caches['propertiesToSearch'] = propertiesToSearch;\n  }\n  if (properties && properties !== '*') {\n    for (const prop of properties) {\n      if (!propertiesToSearch.includes(prop)) {\n        throw createError('UNKNOWN_INDEX', prop, propertiesToSearch.join(', '));\n      }\n    }\n    propertiesToSearch = propertiesToSearch.filter(prop => properties.includes(prop));\n  }\n  // Create the search context and the results\n  const context = await createSearchContext(orama.tokenizer, orama.index, orama.documentsStore, language, params, propertiesToSearch, tokens, await orama.documentsStore.count(docs), timeStart);\n  // If filters are enabled, we need to get the IDs of the documents that match the filters.\n  const hasFilters = Object.keys(params.where ?? {}).length > 0;\n  let whereFiltersIDs = [];\n  if (hasFilters) {\n    whereFiltersIDs = await orama.index.searchByWhereClause(context, index, params.where);\n  }\n  const tokensLength = tokens.length;\n  if (tokensLength || properties && properties.length > 0) {\n    // Now it's time to loop over all the indices and get the documents IDs for every single term\n    const indexesLength = propertiesToSearch.length;\n    for (let i = 0; i < indexesLength; i++) {\n      var _params_boost;\n      const prop = propertiesToSearch[i];\n      if (tokensLength !== 0) {\n        for (let j = 0; j < tokensLength; j++) {\n          const term = tokens[j];\n          // Lookup\n          const scoreList = await orama.index.search(context, index, prop, term);\n          safeArrayPush(context.indexMap[prop][term], scoreList);\n        }\n      } else {\n        context.indexMap[prop][''] = [];\n        const scoreList = await orama.index.search(context, index, prop, '');\n        safeArrayPush(context.indexMap[prop][''], scoreList);\n      }\n      const docIds = context.indexMap[prop];\n      const vals = Object.values(docIds);\n      context.docsIntersection[prop] = prioritizeTokenScores(vals, (params === null || params === void 0 ? void 0 : (_params_boost = params.boost) === null || _params_boost === void 0 ? void 0 : _params_boost[prop]) ?? 1, threshold, tokensLength);\n      const uniqueDocs = context.docsIntersection[prop];\n      const uniqueDocsLength = uniqueDocs.length;\n      for (let i = 0; i < uniqueDocsLength; i++) {\n        const [id, score] = uniqueDocs[i];\n        const prevScore = context.uniqueDocsIDs[id];\n        if (prevScore) {\n          context.uniqueDocsIDs[id] = prevScore + score + 0.5;\n        } else {\n          context.uniqueDocsIDs[id] = score;\n        }\n      }\n    }\n  } else if (tokens.length === 0 && term) {\n    // This case is hard to handle correctly.\n    // For the time being, if tokenizer returns empty array but the term is not empty,\n    // we returns an empty result set\n    context.uniqueDocsIDs = {};\n  } else {\n    context.uniqueDocsIDs = Object.fromEntries(Object.keys(await orama.documentsStore.getAll(orama.data.docs)).map(k => [k, 0]));\n  }\n  // Get unique doc IDs from uniqueDocsIDs map\n  let uniqueDocsArray = Object.entries(context.uniqueDocsIDs).map(([id, score]) => [+id, score]);\n  // If filters are enabled, we need to remove the IDs of the documents that don't match the filters.\n  if (hasFilters) {\n    uniqueDocsArray = intersectFilteredIDs(whereFiltersIDs, uniqueDocsArray);\n  }\n  if (params.sortBy) {\n    if (typeof params.sortBy === 'function') {\n      const ids = uniqueDocsArray.map(([id]) => id);\n      const docs = await orama.documentsStore.getMultiple(orama.data.docs, ids);\n      const docsWithIdAndScore = docs.map((d, i) => [uniqueDocsArray[i][0], uniqueDocsArray[i][1], d]);\n      docsWithIdAndScore.sort(params.sortBy);\n      uniqueDocsArray = docsWithIdAndScore.map(([id, score]) => [id, score]);\n    } else {\n      uniqueDocsArray = await orama.sorter.sortBy(orama.data.sorting, uniqueDocsArray, params.sortBy).then(results => results.map(([id, score]) => [getInternalDocumentId(orama.internalDocumentIDStore, id), score]));\n    }\n  } else {\n    uniqueDocsArray = uniqueDocsArray.sort(sortTokenScorePredicate);\n  }\n  let results;\n  if (!isPreflight && distinctOn) {\n    results = await fetchDocumentsWithDistinct(orama, uniqueDocsArray, offset, limit, distinctOn);\n  } else if (!isPreflight) {\n    results = await fetchDocuments(orama, uniqueDocsArray, offset, limit);\n  }\n  const searchResult = {\n    elapsed: {\n      formatted: '',\n      raw: 0\n    },\n    // We keep the hits array empty if it's a preflight request.\n    hits: [],\n    count: uniqueDocsArray.length\n  };\n  if (typeof results !== 'undefined') {\n    searchResult.hits = results.filter(Boolean);\n  }\n  if (shouldCalculateFacets) {\n    // Populate facets if needed\n    const facets = await getFacets(orama, uniqueDocsArray, params.facets);\n    searchResult.facets = facets;\n  }\n  if (params.groupBy) {\n    searchResult.groups = await getGroups(orama, uniqueDocsArray, params.groupBy);\n  }\n  if (orama.afterSearch) {\n    await runAfterSearch(orama.afterSearch, orama, params, language, searchResult);\n  }\n  // Calculate elapsed time only at the end of the function\n  searchResult.elapsed = await orama.formatElapsedTime((await getNanosecondsTime()) - context.timeStart);\n  return searchResult;\n}\nasync function fetchDocumentsWithDistinct(orama, uniqueDocsArray, offset, limit, distinctOn) {\n  const docs = orama.data.docs;\n  // Keep track which values we already seen\n  const values = new Map();\n  // We cannot know how many results we will have in the end,\n  // so we need cannot pre-allocate the array.\n  const results = [];\n  const resultIDs = new Set();\n  const uniqueDocsArrayLength = uniqueDocsArray.length;\n  let count = 0;\n  for (let i = 0; i < uniqueDocsArrayLength; i++) {\n    const idAndScore = uniqueDocsArray[i];\n    // If there are no more results, just break the loop\n    if (typeof idAndScore === 'undefined') {\n      continue;\n    }\n    const [id, score] = idAndScore;\n    if (resultIDs.has(id)) {\n      continue;\n    }\n    const doc = await orama.documentsStore.get(docs, id);\n    const value = await getNested(doc, distinctOn);\n    if (typeof value === 'undefined' || values.has(value)) {\n      continue;\n    }\n    values.set(value, true);\n    count++;\n    // We shouldn't consider the document if it's not in the offset range\n    if (count <= offset) {\n      continue;\n    }\n    results.push({\n      id: getDocumentIdFromInternalId(orama.internalDocumentIDStore, id),\n      score,\n      document: doc\n    });\n    resultIDs.add(id);\n    // reached the limit, break the loop\n    if (count >= offset + limit) {\n      break;\n    }\n  }\n  return results;\n}\nasync function fetchDocuments(orama, uniqueDocsArray, offset, limit) {\n  const docs = orama.data.docs;\n  const results = Array.from({\n    length: limit\n  });\n  const resultIDs = new Set();\n  // We already have the list of ALL the document IDs containing the search terms.\n  // We loop over them starting from a positional value \"offset\" and ending at \"offset + limit\"\n  // to provide pagination capabilities to the search.\n  for (let i = offset; i < limit + offset; i++) {\n    const idAndScore = uniqueDocsArray[i];\n    // If there are no more results, just break the loop\n    if (typeof idAndScore === 'undefined') {\n      break;\n    }\n    const [id, score] = idAndScore;\n    if (!resultIDs.has(id)) {\n      // We retrieve the full document only AFTER making sure that we really want it.\n      // We never retrieve the full document preventively.\n      const fullDoc = await orama.documentsStore.get(docs, id);\n      results[i] = {\n        id: getDocumentIdFromInternalId(orama.internalDocumentIDStore, id),\n        score,\n        document: fullDoc\n      };\n      resultIDs.add(id);\n    }\n  }\n  return results;\n}","map":{"version":3,"names":["prioritizeTokenScores","getFacets","intersectFilteredIDs","getGroups","runAfterSearch","getDocumentIdFromInternalId","getInternalDocumentId","createError","getNanosecondsTime","getNested","sortTokenScorePredicate","safeArrayPush","defaultBM25Params","k","b","d","createSearchContext","tokenizer","index","documentsStore","language","params","properties","tokens","docsCount","timeStart","indexMap","docsIntersection","prop","tokensMap","token","uniqueDocsIDs","search","orama","relevance","Object","assign","shouldCalculateFacets","facets","keys","length","limit","offset","term","threshold","distinctOn","isPreflight","preflight","docs","data","tokenize","propertiesToSearch","caches","propertiesToSearchWithTypes","getSearchablePropertiesWithTypes","getSearchableProperties","filter","startsWith","includes","join","context","count","hasFilters","where","whereFiltersIDs","searchByWhereClause","tokensLength","indexesLength","i","_params_boost","j","scoreList","docIds","vals","values","boost","uniqueDocs","uniqueDocsLength","id","score","prevScore","fromEntries","getAll","map","uniqueDocsArray","entries","sortBy","ids","getMultiple","docsWithIdAndScore","sort","sorter","sorting","then","results","internalDocumentIDStore","fetchDocumentsWithDistinct","fetchDocuments","searchResult","elapsed","formatted","raw","hits","Boolean","groupBy","groups","afterSearch","formatElapsedTime","Map","resultIDs","Set","uniqueDocsArrayLength","idAndScore","has","doc","get","value","set","push","document","add","Array","from","fullDoc"],"sources":["/home/krug/Coding/JavaScript/Websites/Personal/personal/node_modules/.pnpm/@orama+orama@1.2.11/node_modules/@orama/orama/src/methods/search.ts"],"sourcesContent":["import { prioritizeTokenScores } from '../components/algorithms.js'\nimport { getFacets } from '../components/facets.js'\nimport { intersectFilteredIDs } from '../components/filters.js'\nimport { getGroups } from '../components/groups.js'\nimport { runAfterSearch } from '../components/hooks.js'\nimport {\n  InternalDocumentID,\n  getDocumentIdFromInternalId,\n  getInternalDocumentId,\n} from '../components/internal-document-id-store.js'\nimport { createError } from '../errors.js'\nimport { getNanosecondsTime, getNested, sortTokenScorePredicate, safeArrayPush } from '../utils.js';\nimport type {\n  AnyOrama,\n  BM25Params,\n  CustomSorterFunctionItem,\n  ElapsedTime,\n  IndexMap,\n  LiteralUnion,\n  Result,\n  Results,\n  SearchContext,\n  SearchParams,\n  SearchableValue,\n  TokenMap,\n  TokenScore,\n  Tokenizer,\n  TypedDocument,\n} from '../types.js'\n\nconst defaultBM25Params: BM25Params = {\n  k: 1.2,\n  b: 0.75,\n  d: 0.5,\n}\n\nasync function createSearchContext<T extends AnyOrama, ResultDocument = TypedDocument<T>>(\n  tokenizer: Tokenizer,\n  index: T['index'],\n  documentsStore: T['documentsStore'],\n  language: string | undefined,\n  params: SearchParams<T, ResultDocument>,\n  properties: string[],\n  tokens: string[],\n  docsCount: number,\n  timeStart: bigint,\n): Promise<SearchContext<T, ResultDocument>> {\n  // If filters are enabled, we need to get the IDs of the documents that match the filters.\n  // const hasFilters = Object.keys(params.where ?? {}).length > 0;\n  // let whereFiltersIDs: string[] = [];\n\n  // if (hasFilters) {\n  //   whereFiltersIDs = getWhereFiltersIDs(params.where!, orama);\n  // }\n\n  // indexMap is an object containing all the indexes considered for the current search,\n  // and an array of doc IDs for each token in all the indices.\n  //\n  // Given the search term \"quick brown fox\" on the \"description\" index,\n  // indexMap will look like this:\n  //\n  // {\n  //   description: {\n  //     quick: [doc1, doc2, doc3],\n  //     brown: [doc2, doc4],\n  //     fox:   [doc2]\n  //   }\n  // }\n  const indexMap: IndexMap = {}\n\n  // After we create the indexMap, we need to calculate the intersection\n  // between all the postings lists for each token.\n  // Given the example above, docsIntersection will look like this:\n  //\n  // {\n  //   description: [doc2]\n  // }\n  //\n  // as doc2 is the only document present in all the postings lists for the \"description\" index.\n  const docsIntersection: TokenMap = {}\n\n  for (const prop of properties) {\n    const tokensMap: TokenMap = {}\n    for (const token of tokens) {\n      tokensMap[token] = []\n    }\n    indexMap[prop] = tokensMap\n    docsIntersection[prop] = []\n  }\n\n  return {\n    timeStart,\n    tokenizer,\n    index,\n    documentsStore,\n    language,\n    params,\n    docsCount,\n    uniqueDocsIDs: {},\n    indexMap,\n    docsIntersection,\n  }\n}\n\nexport async function search<T extends AnyOrama, ResultDocument = TypedDocument<T>>(\n  orama: T,\n  params: SearchParams<T, ResultDocument>,\n  language?: string,\n): Promise<Results<ResultDocument>> {\n  const timeStart = await getNanosecondsTime()\n\n  params.relevance = Object.assign(params.relevance ?? {}, defaultBM25Params)\n\n  const shouldCalculateFacets = params.facets && Object.keys(params.facets).length > 0\n  const { limit = 10, offset = 0, term, properties, threshold = 1, distinctOn } = params\n  const isPreflight = params.preflight === true\n\n  const { index, docs } = orama.data\n  const tokens = await orama.tokenizer.tokenize(term ?? '', language)\n\n  // Get searchable string properties\n  let propertiesToSearch = orama.caches['propertiesToSearch'] as string[]\n  if (!propertiesToSearch) {\n    const propertiesToSearchWithTypes = await orama.index.getSearchablePropertiesWithTypes(index)\n\n    propertiesToSearch = await orama.index.getSearchableProperties(index)\n    propertiesToSearch = propertiesToSearch.filter((prop: string) =>\n      propertiesToSearchWithTypes[prop].startsWith('string'),\n    )\n\n    orama.caches['propertiesToSearch'] = propertiesToSearch\n  }\n\n  if (properties && properties !== '*') {\n    for (const prop of properties) {\n      if (!propertiesToSearch.includes(prop as string)) {\n        throw createError('UNKNOWN_INDEX', prop as string, propertiesToSearch.join(', '))\n      }\n    }\n\n    propertiesToSearch = propertiesToSearch.filter((prop: string) => (properties as string[]).includes(prop))\n  }\n\n  // Create the search context and the results\n  const context = await createSearchContext(\n    orama.tokenizer,\n    orama.index,\n    orama.documentsStore,\n    language,\n    params,\n    propertiesToSearch,\n    tokens,\n    await orama.documentsStore.count(docs),\n    timeStart,\n  )\n\n  // If filters are enabled, we need to get the IDs of the documents that match the filters.\n  const hasFilters = Object.keys(params.where ?? {}).length > 0\n  let whereFiltersIDs: InternalDocumentID[] = []\n\n  if (hasFilters) {\n    whereFiltersIDs = await orama.index.searchByWhereClause(context, index, params.where!)\n  }\n\n  const tokensLength = tokens.length\n\n  if (tokensLength || (properties && properties.length > 0)) {\n    // Now it's time to loop over all the indices and get the documents IDs for every single term\n    const indexesLength = propertiesToSearch.length\n    for (let i = 0; i < indexesLength; i++) {\n      const prop = propertiesToSearch[i]\n\n      if (tokensLength !== 0) {\n        for (let j = 0; j < tokensLength; j++) {\n          const term = tokens[j]\n\n          // Lookup\n          const scoreList = await orama.index.search(context, index, prop, term)\n\n          safeArrayPush(context.indexMap[prop][term], scoreList);\n        }\n      } else {\n        context.indexMap[prop][''] = []\n        const scoreList = await orama.index.search(context, index, prop, '')\n        safeArrayPush(context.indexMap[prop][''], scoreList);\n      }\n\n      const docIds = context.indexMap[prop]\n      const vals = Object.values(docIds)\n      context.docsIntersection[prop] = prioritizeTokenScores(vals, params?.boost?.[prop] ?? 1, threshold, tokensLength)\n      const uniqueDocs = context.docsIntersection[prop]\n\n      const uniqueDocsLength = uniqueDocs.length\n      for (let i = 0; i < uniqueDocsLength; i++) {\n        const [id, score] = uniqueDocs[i]\n        const prevScore = context.uniqueDocsIDs[id]\n        if (prevScore) {\n          context.uniqueDocsIDs[id] = prevScore + score + 0.5\n        } else {\n          context.uniqueDocsIDs[id] = score\n        }\n      }\n    }\n  } else if (tokens.length === 0 && term) {\n    // This case is hard to handle correctly.\n    // For the time being, if tokenizer returns empty array but the term is not empty,\n    // we returns an empty result set\n    context.uniqueDocsIDs = {}\n  } else {\n    context.uniqueDocsIDs = Object.fromEntries(\n      Object.keys(await orama.documentsStore.getAll(orama.data.docs)).map(k => [k, 0]),\n    )\n  }\n\n  // Get unique doc IDs from uniqueDocsIDs map\n  let uniqueDocsArray = Object.entries(context.uniqueDocsIDs).map(([id, score]) => [+id, score] as TokenScore)\n\n  // If filters are enabled, we need to remove the IDs of the documents that don't match the filters.\n  if (hasFilters) {\n    uniqueDocsArray = intersectFilteredIDs(whereFiltersIDs, uniqueDocsArray)\n  }\n\n  if (params.sortBy) {\n    if (typeof params.sortBy === 'function') {\n      const ids = uniqueDocsArray.map(([id]) => id)\n      const docs = await orama.documentsStore.getMultiple(orama.data.docs, ids)\n      const docsWithIdAndScore: CustomSorterFunctionItem<ResultDocument>[] = docs.map((d, i) => [\n        uniqueDocsArray[i][0],\n        uniqueDocsArray[i][1],\n        d!,\n      ])\n      docsWithIdAndScore.sort(params.sortBy)\n      uniqueDocsArray = docsWithIdAndScore.map(([id, score]) => [id, score])\n    } else {\n      uniqueDocsArray = await orama.sorter\n        .sortBy(orama.data.sorting, uniqueDocsArray, params.sortBy)\n        .then(results =>\n          results.map(([id, score]) => [getInternalDocumentId(orama.internalDocumentIDStore, id), score]),\n        )\n    }\n  } else {\n    uniqueDocsArray = uniqueDocsArray.sort(sortTokenScorePredicate)\n  }\n\n  let results\n  if (!isPreflight && distinctOn) {\n    results = await fetchDocumentsWithDistinct(orama, uniqueDocsArray, offset, limit, distinctOn)\n  } else if (!isPreflight) {\n    results = await fetchDocuments(orama, uniqueDocsArray, offset, limit)\n  }\n\n  const searchResult: Results<ResultDocument> = {\n    elapsed: {\n      formatted: '',\n      raw: 0,\n    },\n    // We keep the hits array empty if it's a preflight request.\n    hits: [],\n    count: uniqueDocsArray.length,\n  }\n\n  if (typeof results !== 'undefined') {\n    searchResult.hits = results.filter(Boolean)\n  }\n\n  if (shouldCalculateFacets) {\n    // Populate facets if needed\n    const facets = await getFacets(orama, uniqueDocsArray, params.facets!)\n    searchResult.facets = facets\n  }\n\n  if (params.groupBy) {\n    searchResult.groups = await getGroups<T, ResultDocument>(orama, uniqueDocsArray, params.groupBy)\n  }\n\n  if (orama.afterSearch) {\n    await runAfterSearch(orama.afterSearch, orama, params, language, searchResult)\n  }\n\n  // Calculate elapsed time only at the end of the function\n  searchResult.elapsed = (await orama.formatElapsedTime(\n    (await getNanosecondsTime()) - context.timeStart,\n  )) as ElapsedTime\n\n  return searchResult\n}\n\nasync function fetchDocumentsWithDistinct<T extends AnyOrama, ResultDocument extends TypedDocument<T>>(\n  orama: T,\n  uniqueDocsArray: [InternalDocumentID, number][],\n  offset: number,\n  limit: number,\n  distinctOn: LiteralUnion<T['schema']>,\n): Promise<Result<ResultDocument>[]> {\n  const docs = orama.data.docs\n\n  // Keep track which values we already seen\n  const values = new Map<SearchableValue, true>()\n\n  // We cannot know how many results we will have in the end,\n  // so we need cannot pre-allocate the array.\n  const results: Result<ResultDocument>[] = []\n\n  const resultIDs: Set<InternalDocumentID> = new Set()\n  const uniqueDocsArrayLength = uniqueDocsArray.length\n  let count = 0\n  for (let i = 0; i < uniqueDocsArrayLength; i++) {\n    const idAndScore = uniqueDocsArray[i]\n\n    // If there are no more results, just break the loop\n    if (typeof idAndScore === 'undefined') {\n      continue\n    }\n\n    const [id, score] = idAndScore\n\n    if (resultIDs.has(id)) {\n      continue\n    }\n\n    const doc = await orama.documentsStore.get(docs, id)\n    const value = await getNested(doc as object, distinctOn)\n    if (typeof value === 'undefined' || values.has(value)) {\n      continue\n    }\n    values.set(value, true)\n\n    count++\n    // We shouldn't consider the document if it's not in the offset range\n    if (count <= offset) {\n      continue\n    }\n\n    results.push({ id: getDocumentIdFromInternalId(orama.internalDocumentIDStore, id), score, document: doc! })\n    resultIDs.add(id)\n\n    // reached the limit, break the loop\n    if (count >= offset + limit) {\n      break\n    }\n  }\n\n  return results\n}\n\nasync function fetchDocuments<T extends AnyOrama, ResultDocument extends TypedDocument<T>>(\n  orama: T,\n  uniqueDocsArray: [InternalDocumentID, number][],\n  offset: number,\n  limit: number,\n): Promise<Result<ResultDocument>[]> {\n  const docs = orama.data.docs\n\n  const results: Result<ResultDocument>[] = Array.from({\n    length: limit,\n  })\n\n  const resultIDs: Set<InternalDocumentID> = new Set()\n\n  // We already have the list of ALL the document IDs containing the search terms.\n  // We loop over them starting from a positional value \"offset\" and ending at \"offset + limit\"\n  // to provide pagination capabilities to the search.\n  for (let i = offset; i < limit + offset; i++) {\n    const idAndScore = uniqueDocsArray[i]\n\n    // If there are no more results, just break the loop\n    if (typeof idAndScore === 'undefined') {\n      break\n    }\n\n    const [id, score] = idAndScore\n\n    if (!resultIDs.has(id)) {\n      // We retrieve the full document only AFTER making sure that we really want it.\n      // We never retrieve the full document preventively.\n      const fullDoc = await orama.documentsStore.get(docs, id)\n      results[i] = { id: getDocumentIdFromInternalId(orama.internalDocumentIDStore, id), score, document: fullDoc! }\n      resultIDs.add(id)\n    }\n  }\n  return results\n}\n"],"mappings":"AAAA,SAASA,qBAAqB,QAAQ;AACtC,SAASC,SAAS,QAAQ;AAC1B,SAASC,oBAAoB,QAAQ;AACrC,SAASC,SAAS,QAAQ;AAC1B,SAASC,cAAc,QAAQ;AAC/B,SAEEC,2BAA2B,EAC3BC,qBAAqB,QAChB;AACP,SAASC,WAAW,QAAQ;AAC5B,SAASC,kBAAkB,EAAEC,SAAS,EAAEC,uBAAuB,EAAEC,aAAa,QAAQ;AAmBtF,MAAMC,iBAAA,GAAgC;EACpCC,CAAA,EAAG;EACHC,CAAA,EAAG;EACHC,CAAA,EAAG;AACL;AAEA,eAAeC,oBACbC,SAAoB,EACpBC,KAAiB,EACjBC,cAAmC,EACnCC,QAA4B,EAC5BC,MAAuC,EACvCC,UAAoB,EACpBC,MAAgB,EAChBC,SAAiB,EACjBC,SAAiB,EAC0B;EAC3C;EACA;EACA;EAEA;EACA;EACA;EAEA;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EACA,MAAMC,QAAA,GAAqB,CAAC;EAE5B;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EACA,MAAMC,gBAAA,GAA6B,CAAC;EAEpC,KAAK,MAAMC,IAAA,IAAQN,UAAA,EAAY;IAC7B,MAAMO,SAAA,GAAsB,CAAC;IAC7B,KAAK,MAAMC,KAAA,IAASP,MAAA,EAAQ;MAC1BM,SAAS,CAACC,KAAA,CAAM,GAAG,EAAE;IACvB;IACAJ,QAAQ,CAACE,IAAA,CAAK,GAAGC,SAAA;IACjBF,gBAAgB,CAACC,IAAA,CAAK,GAAG,EAAE;EAC7B;EAEA,OAAO;IACLH,SAAA;IACAR,SAAA;IACAC,KAAA;IACAC,cAAA;IACAC,QAAA;IACAC,MAAA;IACAG,SAAA;IACAO,aAAA,EAAe,CAAC;IAChBL,QAAA;IACAC;EACF;AACF;AAEA,OAAO,eAAeK,OACpBC,KAAQ,EACRZ,MAAuC,EACvCD,QAAiB,EACiB;EAClC,MAAMK,SAAA,GAAY,MAAMjB,kBAAA;EAExBa,MAAA,CAAOa,SAAS,GAAGC,MAAA,CAAOC,MAAM,CAACf,MAAA,CAAOa,SAAS,IAAI,CAAC,GAAGtB,iBAAA;EAEzD,MAAMyB,qBAAA,GAAwBhB,MAAA,CAAOiB,MAAM,IAAIH,MAAA,CAAOI,IAAI,CAAClB,MAAA,CAAOiB,MAAM,EAAEE,MAAM,GAAG;EACnF,MAAM;IAAEC,KAAA,GAAQ;IAAIC,MAAA,GAAS;IAAGC,IAAA;IAAMrB,UAAA;IAAYsB,SAAA,GAAY;IAAGC;EAAU,CAAE,GAAGxB,MAAA;EAChF,MAAMyB,WAAA,GAAczB,MAAA,CAAO0B,SAAS,KAAK,IAAI;EAE7C,MAAM;IAAE7B,KAAA;IAAO8B;EAAI,CAAE,GAAGf,KAAA,CAAMgB,IAAI;EAClC,MAAM1B,MAAA,GAAS,MAAMU,KAAA,CAAMhB,SAAS,CAACiC,QAAQ,CAACP,IAAA,IAAQ,IAAIvB,QAAA;EAE1D;EACA,IAAI+B,kBAAA,GAAqBlB,KAAA,CAAMmB,MAAM,CAAC,qBAAqB;EAC3D,IAAI,CAACD,kBAAA,EAAoB;IACvB,MAAME,2BAAA,GAA8B,MAAMpB,KAAA,CAAMf,KAAK,CAACoC,gCAAgC,CAACpC,KAAA;IAEvFiC,kBAAA,GAAqB,MAAMlB,KAAA,CAAMf,KAAK,CAACqC,uBAAuB,CAACrC,KAAA;IAC/DiC,kBAAA,GAAqBA,kBAAA,CAAmBK,MAAM,CAAE5B,IAAA,IAC9CyB,2BAA2B,CAACzB,IAAA,CAAK,CAAC6B,UAAU,CAAC;IAG/CxB,KAAA,CAAMmB,MAAM,CAAC,qBAAqB,GAAGD,kBAAA;EACvC;EAEA,IAAI7B,UAAA,IAAcA,UAAA,KAAe,KAAK;IACpC,KAAK,MAAMM,IAAA,IAAQN,UAAA,EAAY;MAC7B,IAAI,CAAC6B,kBAAA,CAAmBO,QAAQ,CAAC9B,IAAA,GAAiB;QAChD,MAAMrB,WAAA,CAAY,iBAAiBqB,IAAA,EAAgBuB,kBAAA,CAAmBQ,IAAI,CAAC;MAC7E;IACF;IAEAR,kBAAA,GAAqBA,kBAAA,CAAmBK,MAAM,CAAE5B,IAAA,IAAiBN,UAAC,CAAwBoC,QAAQ,CAAC9B,IAAA;EACrG;EAEA;EACA,MAAMgC,OAAA,GAAU,MAAM5C,mBAAA,CACpBiB,KAAA,CAAMhB,SAAS,EACfgB,KAAA,CAAMf,KAAK,EACXe,KAAA,CAAMd,cAAc,EACpBC,QAAA,EACAC,MAAA,EACA8B,kBAAA,EACA5B,MAAA,EACA,MAAMU,KAAA,CAAMd,cAAc,CAAC0C,KAAK,CAACb,IAAA,GACjCvB,SAAA;EAGF;EACA,MAAMqC,UAAA,GAAa3B,MAAA,CAAOI,IAAI,CAAClB,MAAA,CAAO0C,KAAK,IAAI,CAAC,GAAGvB,MAAM,GAAG;EAC5D,IAAIwB,eAAA,GAAwC,EAAE;EAE9C,IAAIF,UAAA,EAAY;IACdE,eAAA,GAAkB,MAAM/B,KAAA,CAAMf,KAAK,CAAC+C,mBAAmB,CAACL,OAAA,EAAS1C,KAAA,EAAOG,MAAA,CAAO0C,KAAK;EACtF;EAEA,MAAMG,YAAA,GAAe3C,MAAA,CAAOiB,MAAM;EAElC,IAAI0B,YAAA,IAAiB5C,UAAA,IAAcA,UAAA,CAAWkB,MAAM,GAAG,GAAI;IACzD;IACA,MAAM2B,aAAA,GAAgBhB,kBAAA,CAAmBX,MAAM;IAC/C,KAAK,IAAI4B,CAAA,GAAI,GAAGA,CAAA,GAAID,aAAA,EAAeC,CAAA,IAAK;UAoBuBC,aAAA;MAnB7D,MAAMzC,IAAA,GAAOuB,kBAAkB,CAACiB,CAAA,CAAE;MAElC,IAAIF,YAAA,KAAiB,GAAG;QACtB,KAAK,IAAII,CAAA,GAAI,GAAGA,CAAA,GAAIJ,YAAA,EAAcI,CAAA,IAAK;UACrC,MAAM3B,IAAA,GAAOpB,MAAM,CAAC+C,CAAA,CAAE;UAEtB;UACA,MAAMC,SAAA,GAAY,MAAMtC,KAAA,CAAMf,KAAK,CAACc,MAAM,CAAC4B,OAAA,EAAS1C,KAAA,EAAOU,IAAA,EAAMe,IAAA;UAEjEhC,aAAA,CAAciD,OAAA,CAAQlC,QAAQ,CAACE,IAAA,CAAK,CAACe,IAAA,CAAK,EAAE4B,SAAA;QAC9C;MACF,OAAO;QACLX,OAAA,CAAQlC,QAAQ,CAACE,IAAA,CAAK,CAAC,GAAG,GAAG,EAAE;QAC/B,MAAM2C,SAAA,GAAY,MAAMtC,KAAA,CAAMf,KAAK,CAACc,MAAM,CAAC4B,OAAA,EAAS1C,KAAA,EAAOU,IAAA,EAAM;QACjEjB,aAAA,CAAciD,OAAA,CAAQlC,QAAQ,CAACE,IAAA,CAAK,CAAC,GAAG,EAAE2C,SAAA;MAC5C;MAEA,MAAMC,MAAA,GAASZ,OAAA,CAAQlC,QAAQ,CAACE,IAAA,CAAK;MACrC,MAAM6C,IAAA,GAAOtC,MAAA,CAAOuC,MAAM,CAACF,MAAA;MAC3BZ,OAAA,CAAQjC,gBAAgB,CAACC,IAAA,CAAK,GAAG5B,qBAAA,CAAsByE,IAAA,EAAM,CAAApD,MAAA,aAAAA,MAAA,wBAAAgD,aAAA,GAAAhD,MAAA,CAAQsD,KAAK,cAAbN,aAAA,uBAAAA,aAAe,CAACzC,IAAA,CAAK,KAAI,GAAGgB,SAAA,EAAWsB,YAAA;MACpG,MAAMU,UAAA,GAAahB,OAAA,CAAQjC,gBAAgB,CAACC,IAAA,CAAK;MAEjD,MAAMiD,gBAAA,GAAmBD,UAAA,CAAWpC,MAAM;MAC1C,KAAK,IAAI4B,CAAA,GAAI,GAAGA,CAAA,GAAIS,gBAAA,EAAkBT,CAAA,IAAK;QACzC,MAAM,CAACU,EAAA,EAAIC,KAAA,CAAM,GAAGH,UAAU,CAACR,CAAA,CAAE;QACjC,MAAMY,SAAA,GAAYpB,OAAA,CAAQ7B,aAAa,CAAC+C,EAAA,CAAG;QAC3C,IAAIE,SAAA,EAAW;UACbpB,OAAA,CAAQ7B,aAAa,CAAC+C,EAAA,CAAG,GAAGE,SAAA,GAAYD,KAAA,GAAQ;QAClD,OAAO;UACLnB,OAAA,CAAQ7B,aAAa,CAAC+C,EAAA,CAAG,GAAGC,KAAA;QAC9B;MACF;IACF;EACF,OAAO,IAAIxD,MAAA,CAAOiB,MAAM,KAAK,KAAKG,IAAA,EAAM;IACtC;IACA;IACA;IACAiB,OAAA,CAAQ7B,aAAa,GAAG,CAAC;EAC3B,OAAO;IACL6B,OAAA,CAAQ7B,aAAa,GAAGI,MAAA,CAAO8C,WAAW,CACxC9C,MAAA,CAAOI,IAAI,CAAC,MAAMN,KAAA,CAAMd,cAAc,CAAC+D,MAAM,CAACjD,KAAA,CAAMgB,IAAI,CAACD,IAAI,GAAGmC,GAAG,CAACtE,CAAA,IAAK,CAACA,CAAA,EAAG,EAAE;EAEnF;EAEA;EACA,IAAIuE,eAAA,GAAkBjD,MAAA,CAAOkD,OAAO,CAACzB,OAAA,CAAQ7B,aAAa,EAAEoD,GAAG,CAAC,CAAC,CAACL,EAAA,EAAIC,KAAA,CAAM,KAAK,CAAC,CAACD,EAAA,EAAIC,KAAA,CAAM;EAE7F;EACA,IAAIjB,UAAA,EAAY;IACdsB,eAAA,GAAkBlF,oBAAA,CAAqB8D,eAAA,EAAiBoB,eAAA;EAC1D;EAEA,IAAI/D,MAAA,CAAOiE,MAAM,EAAE;IACjB,IAAI,OAAOjE,MAAA,CAAOiE,MAAM,KAAK,YAAY;MACvC,MAAMC,GAAA,GAAMH,eAAA,CAAgBD,GAAG,CAAC,CAAC,CAACL,EAAA,CAAG,KAAKA,EAAA;MAC1C,MAAM9B,IAAA,GAAO,MAAMf,KAAA,CAAMd,cAAc,CAACqE,WAAW,CAACvD,KAAA,CAAMgB,IAAI,CAACD,IAAI,EAAEuC,GAAA;MACrE,MAAME,kBAAA,GAAiEzC,IAAA,CAAKmC,GAAG,CAAC,CAACpE,CAAA,EAAGqD,CAAA,KAAM,CACxFgB,eAAe,CAAChB,CAAA,CAAE,CAAC,EAAE,EACrBgB,eAAe,CAAChB,CAAA,CAAE,CAAC,EAAE,EACrBrD,CAAA,CACD;MACD0E,kBAAA,CAAmBC,IAAI,CAACrE,MAAA,CAAOiE,MAAM;MACrCF,eAAA,GAAkBK,kBAAA,CAAmBN,GAAG,CAAC,CAAC,CAACL,EAAA,EAAIC,KAAA,CAAM,KAAK,CAACD,EAAA,EAAIC,KAAA,CAAM;IACvE,OAAO;MACLK,eAAA,GAAkB,MAAMnD,KAAA,CAAM0D,MAAM,CACjCL,MAAM,CAACrD,KAAA,CAAMgB,IAAI,CAAC2C,OAAO,EAAER,eAAA,EAAiB/D,MAAA,CAAOiE,MAAM,EACzDO,IAAI,CAACC,OAAA,IACJA,OAAA,CAAQX,GAAG,CAAC,CAAC,CAACL,EAAA,EAAIC,KAAA,CAAM,KAAK,CAACzE,qBAAA,CAAsB2B,KAAA,CAAM8D,uBAAuB,EAAEjB,EAAA,GAAKC,KAAA,CAAM;IAEpG;EACF,OAAO;IACLK,eAAA,GAAkBA,eAAA,CAAgBM,IAAI,CAAChF,uBAAA;EACzC;EAEA,IAAIoF,OAAA;EACJ,IAAI,CAAChD,WAAA,IAAeD,UAAA,EAAY;IAC9BiD,OAAA,GAAU,MAAME,0BAAA,CAA2B/D,KAAA,EAAOmD,eAAA,EAAiB1C,MAAA,EAAQD,KAAA,EAAOI,UAAA;EACpF,OAAO,IAAI,CAACC,WAAA,EAAa;IACvBgD,OAAA,GAAU,MAAMG,cAAA,CAAehE,KAAA,EAAOmD,eAAA,EAAiB1C,MAAA,EAAQD,KAAA;EACjE;EAEA,MAAMyD,YAAA,GAAwC;IAC5CC,OAAA,EAAS;MACPC,SAAA,EAAW;MACXC,GAAA,EAAK;IACP;IACA;IACAC,IAAA,EAAM,EAAE;IACRzC,KAAA,EAAOuB,eAAA,CAAgB5C;EACzB;EAEA,IAAI,OAAOsD,OAAA,KAAY,aAAa;IAClCI,YAAA,CAAaI,IAAI,GAAGR,OAAA,CAAQtC,MAAM,CAAC+C,OAAA;EACrC;EAEA,IAAIlE,qBAAA,EAAuB;IACzB;IACA,MAAMC,MAAA,GAAS,MAAMrC,SAAA,CAAUgC,KAAA,EAAOmD,eAAA,EAAiB/D,MAAA,CAAOiB,MAAM;IACpE4D,YAAA,CAAa5D,MAAM,GAAGA,MAAA;EACxB;EAEA,IAAIjB,MAAA,CAAOmF,OAAO,EAAE;IAClBN,YAAA,CAAaO,MAAM,GAAG,MAAMtG,SAAA,CAA6B8B,KAAA,EAAOmD,eAAA,EAAiB/D,MAAA,CAAOmF,OAAO;EACjG;EAEA,IAAIvE,KAAA,CAAMyE,WAAW,EAAE;IACrB,MAAMtG,cAAA,CAAe6B,KAAA,CAAMyE,WAAW,EAAEzE,KAAA,EAAOZ,MAAA,EAAQD,QAAA,EAAU8E,YAAA;EACnE;EAEA;EACAA,YAAA,CAAaC,OAAO,GAAI,MAAMlE,KAAA,CAAM0E,iBAAiB,CACnD,OAAOnG,kBAAA,MAAwBoD,OAAA,CAAQnC,SAAS;EAGlD,OAAOyE,YAAA;AACT;AAEA,eAAeF,2BACb/D,KAAQ,EACRmD,eAA+C,EAC/C1C,MAAc,EACdD,KAAa,EACbI,UAAqC,EACF;EACnC,MAAMG,IAAA,GAAOf,KAAA,CAAMgB,IAAI,CAACD,IAAI;EAE5B;EACA,MAAM0B,MAAA,GAAS,IAAIkC,GAAA;EAEnB;EACA;EACA,MAAMd,OAAA,GAAoC,EAAE;EAE5C,MAAMe,SAAA,GAAqC,IAAIC,GAAA;EAC/C,MAAMC,qBAAA,GAAwB3B,eAAA,CAAgB5C,MAAM;EACpD,IAAIqB,KAAA,GAAQ;EACZ,KAAK,IAAIO,CAAA,GAAI,GAAGA,CAAA,GAAI2C,qBAAA,EAAuB3C,CAAA,IAAK;IAC9C,MAAM4C,UAAA,GAAa5B,eAAe,CAAChB,CAAA,CAAE;IAErC;IACA,IAAI,OAAO4C,UAAA,KAAe,aAAa;MACrC;IACF;IAEA,MAAM,CAAClC,EAAA,EAAIC,KAAA,CAAM,GAAGiC,UAAA;IAEpB,IAAIH,SAAA,CAAUI,GAAG,CAACnC,EAAA,GAAK;MACrB;IACF;IAEA,MAAMoC,GAAA,GAAM,MAAMjF,KAAA,CAAMd,cAAc,CAACgG,GAAG,CAACnE,IAAA,EAAM8B,EAAA;IACjD,MAAMsC,KAAA,GAAQ,MAAM3G,SAAA,CAAUyG,GAAA,EAAerE,UAAA;IAC7C,IAAI,OAAOuE,KAAA,KAAU,eAAe1C,MAAA,CAAOuC,GAAG,CAACG,KAAA,GAAQ;MACrD;IACF;IACA1C,MAAA,CAAO2C,GAAG,CAACD,KAAA,EAAO,IAAI;IAEtBvD,KAAA;IACA;IACA,IAAIA,KAAA,IAASnB,MAAA,EAAQ;MACnB;IACF;IAEAoD,OAAA,CAAQwB,IAAI,CAAC;MAAExC,EAAA,EAAIzE,2BAAA,CAA4B4B,KAAA,CAAM8D,uBAAuB,EAAEjB,EAAA;MAAKC,KAAA;MAAOwC,QAAA,EAAUL;IAAK;IACzGL,SAAA,CAAUW,GAAG,CAAC1C,EAAA;IAEd;IACA,IAAIjB,KAAA,IAASnB,MAAA,GAASD,KAAA,EAAO;MAC3B;IACF;EACF;EAEA,OAAOqD,OAAA;AACT;AAEA,eAAeG,eACbhE,KAAQ,EACRmD,eAA+C,EAC/C1C,MAAc,EACdD,KAAa,EACsB;EACnC,MAAMO,IAAA,GAAOf,KAAA,CAAMgB,IAAI,CAACD,IAAI;EAE5B,MAAM8C,OAAA,GAAoC2B,KAAA,CAAMC,IAAI,CAAC;IACnDlF,MAAA,EAAQC;EACV;EAEA,MAAMoE,SAAA,GAAqC,IAAIC,GAAA;EAE/C;EACA;EACA;EACA,KAAK,IAAI1C,CAAA,GAAI1B,MAAA,EAAQ0B,CAAA,GAAI3B,KAAA,GAAQC,MAAA,EAAQ0B,CAAA,IAAK;IAC5C,MAAM4C,UAAA,GAAa5B,eAAe,CAAChB,CAAA,CAAE;IAErC;IACA,IAAI,OAAO4C,UAAA,KAAe,aAAa;MACrC;IACF;IAEA,MAAM,CAAClC,EAAA,EAAIC,KAAA,CAAM,GAAGiC,UAAA;IAEpB,IAAI,CAACH,SAAA,CAAUI,GAAG,CAACnC,EAAA,GAAK;MACtB;MACA;MACA,MAAM6C,OAAA,GAAU,MAAM1F,KAAA,CAAMd,cAAc,CAACgG,GAAG,CAACnE,IAAA,EAAM8B,EAAA;MACrDgB,OAAO,CAAC1B,CAAA,CAAE,GAAG;QAAEU,EAAA,EAAIzE,2BAAA,CAA4B4B,KAAA,CAAM8D,uBAAuB,EAAEjB,EAAA;QAAKC,KAAA;QAAOwC,QAAA,EAAUI;MAAS;MAC7Gd,SAAA,CAAUW,GAAG,CAAC1C,EAAA;IAChB;EACF;EACA,OAAOgB,OAAA;AACT"},"metadata":{},"sourceType":"module","externalDependencies":[]}