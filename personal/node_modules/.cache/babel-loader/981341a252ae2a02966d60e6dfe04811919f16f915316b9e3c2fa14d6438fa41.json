{"ast":null,"code":"import { createError } from '../../errors.js';\nimport { replaceDiacritics } from './diacritics.js';\nimport { SPLITTERS, SUPPORTED_LANGUAGES } from './languages.js';\nimport { stopWords as defaultStopWords } from './stop-words/index.js';\nimport { stemmer as english } from './english-stemmer.js';\nfunction normalizeToken(prop, token) {\n  var _this_stopWords;\n  const key = `${this.language}:${prop}:${token}`;\n  if (this.normalizationCache.has(key)) {\n    return this.normalizationCache.get(key);\n  }\n  // Remove stopwords if enabled\n  if ((_this_stopWords = this.stopWords) === null || _this_stopWords === void 0 ? void 0 : _this_stopWords.includes(token)) {\n    this.normalizationCache.set(key, '');\n    return '';\n  }\n  // Apply stemming if enabled\n  if (this.stemmer && !this.stemmerSkipProperties.has(prop)) {\n    token = this.stemmer(token);\n  }\n  token = replaceDiacritics(token);\n  this.normalizationCache.set(key, token);\n  return token;\n}\n/* c8 ignore next 10 */\nfunction trim(text) {\n  while (text[text.length - 1] === '') {\n    text.pop();\n  }\n  while (text[0] === '') {\n    text.shift();\n  }\n  return text;\n}\nfunction tokenize(input, language, prop) {\n  if (language && language !== this.language) {\n    throw createError('LANGUAGE_NOT_SUPPORTED', language);\n  }\n  /* c8 ignore next 3 */\n  if (typeof input !== 'string') {\n    return [input];\n  }\n  const splitRule = SPLITTERS[this.language];\n  const tokens = input.toLowerCase().split(splitRule).map(this.normalizeToken.bind(this, prop ?? '')).filter(Boolean);\n  const trimTokens = trim(tokens);\n  if (!this.allowDuplicates) {\n    return Array.from(new Set(trimTokens));\n  }\n  return trimTokens;\n}\nexport async function createTokenizer() {\n  let config = arguments.length > 0 && arguments[0] !== undefined ? arguments[0] : {};\n  if (!config.language) {\n    config.language = 'english';\n  } else if (!SUPPORTED_LANGUAGES.includes(config.language)) {\n    throw createError('LANGUAGE_NOT_SUPPORTED', config.language);\n  }\n  // Handle stemming - It is disabled by default\n  let stemmer;\n  if (config.stemming || config.stemmer && !('stemming' in config)) {\n    if (config.stemmer) {\n      if (typeof config.stemmer !== 'function') {\n        throw createError('INVALID_STEMMER_FUNCTION_TYPE');\n      }\n      stemmer = config.stemmer;\n    } else {\n      if (config.language === 'english') {\n        stemmer = english;\n      } else {\n        throw createError('MISSING_STEMMER', config.language);\n      }\n    }\n  }\n  // Handle stopwords\n  let stopWords;\n  if (config.stopWords !== false) {\n    stopWords = defaultStopWords[config.language] ?? [];\n    if (Array.isArray(config.stopWords)) {\n      stopWords = config.stopWords;\n    } else if (typeof config.stopWords === 'function') {\n      stopWords = await config.stopWords(stopWords);\n    } else if (config.stopWords) {\n      throw createError('CUSTOM_STOP_WORDS_MUST_BE_FUNCTION_OR_ARRAY');\n    }\n    // Make sure stopWords is just an array of strings\n    if (!Array.isArray(stopWords)) {\n      throw createError('CUSTOM_STOP_WORDS_MUST_BE_FUNCTION_OR_ARRAY');\n    }\n    for (const s of stopWords) {\n      if (typeof s !== 'string') {\n        throw createError('CUSTOM_STOP_WORDS_MUST_BE_FUNCTION_OR_ARRAY');\n      }\n    }\n  }\n  // Create the tokenizer\n  const tokenizer = {\n    tokenize,\n    language: config.language,\n    stemmer,\n    stemmerSkipProperties: new Set(config.stemmerSkipProperties ? [config.stemmerSkipProperties].flat() : []),\n    stopWords,\n    allowDuplicates: Boolean(config.allowDuplicates),\n    normalizeToken,\n    normalizationCache: new Map()\n  };\n  tokenizer.tokenize = tokenize.bind(tokenizer);\n  tokenizer.normalizeToken = normalizeToken;\n  return tokenizer;\n}","map":{"version":3,"names":["createError","replaceDiacritics","SPLITTERS","SUPPORTED_LANGUAGES","stopWords","defaultStopWords","stemmer","english","normalizeToken","prop","token","_this_stopWords","key","language","normalizationCache","has","get","includes","set","stemmerSkipProperties","trim","text","length","pop","shift","tokenize","input","splitRule","tokens","toLowerCase","split","map","bind","filter","Boolean","trimTokens","allowDuplicates","Array","from","Set","createTokenizer","config","arguments","undefined","stemming","isArray","s","tokenizer","flat","Map"],"sources":["/home/krug/Coding/JavaScript/Websites/Personal/personal/node_modules/.pnpm/@orama+orama@1.0.3/node_modules/@orama/orama/src/components/tokenizer/index.ts"],"sourcesContent":["import { createError } from '../../errors.js'\nimport { Stemmer, Tokenizer, DefaultTokenizerConfig } from '../../types.js'\nimport { replaceDiacritics } from './diacritics.js'\nimport { Language, SPLITTERS, SUPPORTED_LANGUAGES } from './languages.js'\nimport { stopWords as defaultStopWords } from './stop-words/index.js'\nimport { stemmer as english } from './english-stemmer.js'\n\ninterface DefaultTokenizer extends Tokenizer {\n  language: Language\n  stemmer?: Stemmer\n  stemmerSkipProperties: Set<string>\n  stopWords?: string[]\n  allowDuplicates: boolean\n  normalizationCache: Map<string, string>\n  normalizeToken(this: DefaultTokenizer, token: string, prop: string | undefined): string\n}\n\nfunction normalizeToken(this: DefaultTokenizer, prop: string, token: string): string {\n  const key = `${this.language}:${prop}:${token}`\n\n  if (this.normalizationCache.has(key)) {\n    return this.normalizationCache.get(key)!\n  }\n\n  // Remove stopwords if enabled\n  if (this.stopWords?.includes(token)) {\n    this.normalizationCache.set(key, '')\n    return ''\n  }\n\n  // Apply stemming if enabled\n  if (this.stemmer && !this.stemmerSkipProperties.has(prop)) {\n    token = this.stemmer(token)\n  }\n\n  token = replaceDiacritics(token)\n  this.normalizationCache.set(key, token)\n  return token\n}\n\n/* c8 ignore next 10 */\nfunction trim(text: string[]): string[] {\n  while (text[text.length - 1] === '') {\n    text.pop()\n  }\n  while (text[0] === '') {\n    text.shift()\n  }\n  return text\n}\n\nfunction tokenize(this: DefaultTokenizer, input: string, language?: string, prop?: string): string[] {\n  if (language && language !== this.language) {\n    throw createError('LANGUAGE_NOT_SUPPORTED', language)\n  }\n\n  /* c8 ignore next 3 */\n  if (typeof input !== 'string') {\n    return [input]\n  }\n\n  const splitRule = SPLITTERS[this.language]\n  const tokens = input\n    .toLowerCase()\n    .split(splitRule)\n    .map(this.normalizeToken.bind(this, prop ?? ''))\n    .filter(Boolean)\n  const trimTokens = trim(tokens)\n\n  if (!this.allowDuplicates) {\n    return Array.from(new Set(trimTokens))\n  }\n\n  return trimTokens\n}\n\nexport async function createTokenizer(config: DefaultTokenizerConfig = {}): Promise<DefaultTokenizer> {\n  if (!config.language) {\n    config.language = 'english'\n  } else if (!SUPPORTED_LANGUAGES.includes(config.language)) {\n    throw createError('LANGUAGE_NOT_SUPPORTED', config.language)\n  }\n\n  // Handle stemming - It is disabled by default\n  let stemmer: Stemmer | undefined\n\n  if (config.stemming || (config.stemmer && !('stemming' in config))) {\n    if (config.stemmer) {\n      if (typeof config.stemmer !== 'function') {\n        throw createError('INVALID_STEMMER_FUNCTION_TYPE')\n      }\n\n      stemmer = config.stemmer\n    } else {\n      if (config.language === 'english') {\n        stemmer = english\n      } else {\n        throw createError('MISSING_STEMMER', config.language)\n      }\n    }\n  }\n\n  // Handle stopwords\n  let stopWords: string[] | undefined\n\n  if (config.stopWords !== false) {\n    stopWords = defaultStopWords[config.language] ?? []\n\n    if (Array.isArray(config.stopWords)) {\n      stopWords = config.stopWords\n    } else if (typeof config.stopWords === 'function') {\n      stopWords = await config.stopWords(stopWords)\n    } else if (config.stopWords) {\n      throw createError('CUSTOM_STOP_WORDS_MUST_BE_FUNCTION_OR_ARRAY')\n    }\n\n    // Make sure stopWords is just an array of strings\n    if (!Array.isArray(stopWords)) {\n      throw createError('CUSTOM_STOP_WORDS_MUST_BE_FUNCTION_OR_ARRAY')\n    }\n\n    for (const s of stopWords) {\n      if (typeof s !== 'string') {\n        throw createError('CUSTOM_STOP_WORDS_MUST_BE_FUNCTION_OR_ARRAY')\n      }\n    }\n  }\n\n  // Create the tokenizer\n  const tokenizer: DefaultTokenizer = {\n    tokenize,\n    language: config.language,\n    stemmer,\n    stemmerSkipProperties: new Set(config.stemmerSkipProperties ? [config.stemmerSkipProperties].flat() : []),\n    stopWords,\n    allowDuplicates: Boolean(config.allowDuplicates),\n    normalizeToken,\n    normalizationCache: new Map(),\n  }\n\n  tokenizer.tokenize = tokenize.bind(tokenizer)\n  tokenizer.normalizeToken = normalizeToken\n\n  return tokenizer\n}\n"],"mappings":"AAAA,SAASA,WAAW,QAAQ;AAE5B,SAASC,iBAAiB,QAAQ;AAClC,SAAmBC,SAAS,EAAEC,mBAAmB,QAAQ;AACzD,SAASC,SAAA,IAAaC,gBAAgB,QAAQ;AAC9C,SAASC,OAAA,IAAWC,OAAO,QAAQ;AAYnC,SAASC,eAAuCC,IAAY,EAAEC,KAAa,EAAU;MAQ/EC,eAAA;EAPJ,MAAMC,GAAA,GAAO,GAAE,IAAI,CAACC,QAAS,IAAGJ,IAAK,IAAGC,KAAM,EAAC;EAE/C,IAAI,IAAI,CAACI,kBAAkB,CAACC,GAAG,CAACH,GAAA,GAAM;IACpC,OAAO,IAAI,CAACE,kBAAkB,CAACE,GAAG,CAACJ,GAAA;EACrC;EAEA;EACA,IAAI,CAAAD,eAAA,OAAI,CAACP,SAAS,cAAdO,eAAA,uBAAAA,eAAA,CAAgBM,QAAA,CAASP,KAAA,GAAQ;IACnC,IAAI,CAACI,kBAAkB,CAACI,GAAG,CAACN,GAAA,EAAK;IACjC,OAAO;EACT;EAEA;EACA,IAAI,IAAI,CAACN,OAAO,IAAI,CAAC,IAAI,CAACa,qBAAqB,CAACJ,GAAG,CAACN,IAAA,GAAO;IACzDC,KAAA,GAAQ,IAAI,CAACJ,OAAO,CAACI,KAAA;EACvB;EAEAA,KAAA,GAAQT,iBAAA,CAAkBS,KAAA;EAC1B,IAAI,CAACI,kBAAkB,CAACI,GAAG,CAACN,GAAA,EAAKF,KAAA;EACjC,OAAOA,KAAA;AACT;AAEA;AACA,SAASU,KAAKC,IAAc,EAAY;EACtC,OAAOA,IAAI,CAACA,IAAA,CAAKC,MAAM,GAAG,EAAE,KAAK,IAAI;IACnCD,IAAA,CAAKE,GAAG;EACV;EACA,OAAOF,IAAI,CAAC,EAAE,KAAK,IAAI;IACrBA,IAAA,CAAKG,KAAK;EACZ;EACA,OAAOH,IAAA;AACT;AAEA,SAASI,SAAiCC,KAAa,EAAEb,QAAiB,EAAEJ,IAAa,EAAY;EACnG,IAAII,QAAA,IAAYA,QAAA,KAAa,IAAI,CAACA,QAAQ,EAAE;IAC1C,MAAMb,WAAA,CAAY,0BAA0Ba,QAAA;EAC9C;EAEA;EACA,IAAI,OAAOa,KAAA,KAAU,UAAU;IAC7B,OAAO,CAACA,KAAA,CAAM;EAChB;EAEA,MAAMC,SAAA,GAAYzB,SAAS,CAAC,IAAI,CAACW,QAAQ,CAAC;EAC1C,MAAMe,MAAA,GAASF,KAAA,CACZG,WAAW,GACXC,KAAK,CAACH,SAAA,EACNI,GAAG,CAAC,IAAI,CAACvB,cAAc,CAACwB,IAAI,CAAC,IAAI,EAAEvB,IAAA,IAAQ,KAC3CwB,MAAM,CAACC,OAAA;EACV,MAAMC,UAAA,GAAaf,IAAA,CAAKQ,MAAA;EAExB,IAAI,CAAC,IAAI,CAACQ,eAAe,EAAE;IACzB,OAAOC,KAAA,CAAMC,IAAI,CAAC,IAAIC,GAAA,CAAIJ,UAAA;EAC5B;EAEA,OAAOA,UAAA;AACT;AAEA,OAAO,eAAeK,gBAAA,EAAgF;EAAA,IAAhEC,MAAA,GAAAC,SAAA,CAAApB,MAAA,QAAAoB,SAAA,QAAAC,SAAA,GAAAD,SAAA,MAAiC,CAAC,CAAC;EACvE,IAAI,CAACD,MAAA,CAAO5B,QAAQ,EAAE;IACpB4B,MAAA,CAAO5B,QAAQ,GAAG;EACpB,OAAO,IAAI,CAACV,mBAAA,CAAoBc,QAAQ,CAACwB,MAAA,CAAO5B,QAAQ,GAAG;IACzD,MAAMb,WAAA,CAAY,0BAA0ByC,MAAA,CAAO5B,QAAQ;EAC7D;EAEA;EACA,IAAIP,OAAA;EAEJ,IAAImC,MAAA,CAAOG,QAAQ,IAAKH,MAAA,CAAOnC,OAAO,IAAI,EAAE,cAAcmC,MAAK,GAAK;IAClE,IAAIA,MAAA,CAAOnC,OAAO,EAAE;MAClB,IAAI,OAAOmC,MAAA,CAAOnC,OAAO,KAAK,YAAY;QACxC,MAAMN,WAAA,CAAY;MACpB;MAEAM,OAAA,GAAUmC,MAAA,CAAOnC,OAAO;IAC1B,OAAO;MACL,IAAImC,MAAA,CAAO5B,QAAQ,KAAK,WAAW;QACjCP,OAAA,GAAUC,OAAA;MACZ,OAAO;QACL,MAAMP,WAAA,CAAY,mBAAmByC,MAAA,CAAO5B,QAAQ;MACtD;IACF;EACF;EAEA;EACA,IAAIT,SAAA;EAEJ,IAAIqC,MAAA,CAAOrC,SAAS,KAAK,KAAK,EAAE;IAC9BA,SAAA,GAAYC,gBAAgB,CAACoC,MAAA,CAAO5B,QAAQ,CAAC,IAAI,EAAE;IAEnD,IAAIwB,KAAA,CAAMQ,OAAO,CAACJ,MAAA,CAAOrC,SAAS,GAAG;MACnCA,SAAA,GAAYqC,MAAA,CAAOrC,SAAS;IAC9B,OAAO,IAAI,OAAOqC,MAAA,CAAOrC,SAAS,KAAK,YAAY;MACjDA,SAAA,GAAY,MAAMqC,MAAA,CAAOrC,SAAS,CAACA,SAAA;IACrC,OAAO,IAAIqC,MAAA,CAAOrC,SAAS,EAAE;MAC3B,MAAMJ,WAAA,CAAY;IACpB;IAEA;IACA,IAAI,CAACqC,KAAA,CAAMQ,OAAO,CAACzC,SAAA,GAAY;MAC7B,MAAMJ,WAAA,CAAY;IACpB;IAEA,KAAK,MAAM8C,CAAA,IAAK1C,SAAA,EAAW;MACzB,IAAI,OAAO0C,CAAA,KAAM,UAAU;QACzB,MAAM9C,WAAA,CAAY;MACpB;IACF;EACF;EAEA;EACA,MAAM+C,SAAA,GAA8B;IAClCtB,QAAA;IACAZ,QAAA,EAAU4B,MAAA,CAAO5B,QAAQ;IACzBP,OAAA;IACAa,qBAAA,EAAuB,IAAIoB,GAAA,CAAIE,MAAA,CAAOtB,qBAAqB,GAAG,CAACsB,MAAA,CAAOtB,qBAAqB,CAAC,CAAC6B,IAAI,KAAK,EAAE;IACxG5C,SAAA;IACAgC,eAAA,EAAiBF,OAAA,CAAQO,MAAA,CAAOL,eAAe;IAC/C5B,cAAA;IACAM,kBAAA,EAAoB,IAAImC,GAAA;EAC1B;EAEAF,SAAA,CAAUtB,QAAQ,GAAGA,QAAA,CAASO,IAAI,CAACe,SAAA;EACnCA,SAAA,CAAUvC,cAAc,GAAGA,cAAA;EAE3B,OAAOuC,SAAA;AACT"},"metadata":{},"sourceType":"module","externalDependencies":[]}