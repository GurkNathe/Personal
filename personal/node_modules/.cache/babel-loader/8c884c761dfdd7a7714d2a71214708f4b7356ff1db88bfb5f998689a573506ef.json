{"ast":null,"code":"import _regeneratorRuntime from \"/home/krug/Coding/JavaScript/Websites/Personal/personal/node_modules/.pnpm/@babel+runtime@7.22.3/node_modules/@babel/runtime/helpers/esm/regeneratorRuntime.js\";\nimport _createForOfIteratorHelper from \"/home/krug/Coding/JavaScript/Websites/Personal/personal/node_modules/.pnpm/@babel+runtime@7.22.3/node_modules/@babel/runtime/helpers/esm/createForOfIteratorHelper.js\";\nimport _asyncToGenerator from \"/home/krug/Coding/JavaScript/Websites/Personal/personal/node_modules/.pnpm/@babel+runtime@7.22.3/node_modules/@babel/runtime/helpers/esm/asyncToGenerator.js\";\nimport { createError } from '../../errors.js';\nimport { replaceDiacritics } from './diacritics.js';\nimport { SPLITTERS, SUPPORTED_LANGUAGES } from './languages.js';\nimport { stopWords as defaultStopWords } from './stop-words/index.js';\nimport { stemmer as english } from './english-stemmer.js';\nfunction normalizeToken(prop, token) {\n  var _this_stopWords;\n  var key = \"\".concat(this.language, \":\").concat(prop, \":\").concat(token);\n  if (this.normalizationCache.has(key)) {\n    return this.normalizationCache.get(key);\n  }\n  // Remove stopwords if enabled\n  if ((_this_stopWords = this.stopWords) === null || _this_stopWords === void 0 ? void 0 : _this_stopWords.includes(token)) {\n    this.normalizationCache.set(key, '');\n    return '';\n  }\n  // Apply stemming if enabled\n  if (this.stemmer && !this.stemmerSkipProperties.has(prop)) {\n    token = this.stemmer(token);\n  }\n  token = replaceDiacritics(token);\n  this.normalizationCache.set(key, token);\n  return token;\n}\n/* c8 ignore next 10 */\nfunction trim(text) {\n  while (text[text.length - 1] === '') {\n    text.pop();\n  }\n  while (text[0] === '') {\n    text.shift();\n  }\n  return text;\n}\nfunction tokenize(input, language, prop) {\n  if (language && language !== this.language) {\n    throw createError('LANGUAGE_NOT_SUPPORTED', language);\n  }\n  /* c8 ignore next 3 */\n  if (typeof input !== 'string') {\n    return [input];\n  }\n  var splitRule = SPLITTERS[this.language];\n  var tokens = input.toLowerCase().split(splitRule).map(this.normalizeToken.bind(this, prop !== null && prop !== void 0 ? prop : '')).filter(Boolean);\n  var trimTokens = trim(tokens);\n  if (!this.allowDuplicates) {\n    return Array.from(new Set(trimTokens));\n  }\n  return trimTokens;\n}\nexport function createTokenizer() {\n  return _createTokenizer.apply(this, arguments);\n}\nfunction _createTokenizer() {\n  _createTokenizer = _asyncToGenerator( /*#__PURE__*/_regeneratorRuntime().mark(function _callee() {\n    var config,\n      stemmer,\n      stopWords,\n      _defaultStopWords$con,\n      _iterator,\n      _step,\n      s,\n      tokenizer,\n      _args = arguments;\n    return _regeneratorRuntime().wrap(function _callee$(_context) {\n      while (1) switch (_context.prev = _context.next) {\n        case 0:\n          config = _args.length > 0 && _args[0] !== undefined ? _args[0] : {};\n          if (config.language) {\n            _context.next = 5;\n            break;\n          }\n          config.language = 'english';\n          _context.next = 7;\n          break;\n        case 5:\n          if (SUPPORTED_LANGUAGES.includes(config.language)) {\n            _context.next = 7;\n            break;\n          }\n          throw createError('LANGUAGE_NOT_SUPPORTED', config.language);\n        case 7:\n          if (!(config.stemming || config.stemmer && !('stemming' in config))) {\n            _context.next = 19;\n            break;\n          }\n          if (!config.stemmer) {\n            _context.next = 14;\n            break;\n          }\n          if (!(typeof config.stemmer !== 'function')) {\n            _context.next = 11;\n            break;\n          }\n          throw createError('INVALID_STEMMER_FUNCTION_TYPE');\n        case 11:\n          stemmer = config.stemmer;\n          _context.next = 19;\n          break;\n        case 14:\n          if (!(config.language === 'english')) {\n            _context.next = 18;\n            break;\n          }\n          stemmer = english;\n          _context.next = 19;\n          break;\n        case 18:\n          throw createError('MISSING_STEMMER', config.language);\n        case 19:\n          if (!(config.stopWords !== false)) {\n            _context.next = 52;\n            break;\n          }\n          stopWords = (_defaultStopWords$con = defaultStopWords[config.language]) !== null && _defaultStopWords$con !== void 0 ? _defaultStopWords$con : [];\n          if (!Array.isArray(config.stopWords)) {\n            _context.next = 25;\n            break;\n          }\n          stopWords = config.stopWords;\n          _context.next = 33;\n          break;\n        case 25:\n          if (!(typeof config.stopWords === 'function')) {\n            _context.next = 31;\n            break;\n          }\n          _context.next = 28;\n          return config.stopWords(stopWords);\n        case 28:\n          stopWords = _context.sent;\n          _context.next = 33;\n          break;\n        case 31:\n          if (!config.stopWords) {\n            _context.next = 33;\n            break;\n          }\n          throw createError('CUSTOM_STOP_WORDS_MUST_BE_FUNCTION_OR_ARRAY');\n        case 33:\n          if (Array.isArray(stopWords)) {\n            _context.next = 35;\n            break;\n          }\n          throw createError('CUSTOM_STOP_WORDS_MUST_BE_FUNCTION_OR_ARRAY');\n        case 35:\n          _iterator = _createForOfIteratorHelper(stopWords);\n          _context.prev = 36;\n          _iterator.s();\n        case 38:\n          if ((_step = _iterator.n()).done) {\n            _context.next = 44;\n            break;\n          }\n          s = _step.value;\n          if (!(typeof s !== 'string')) {\n            _context.next = 42;\n            break;\n          }\n          throw createError('CUSTOM_STOP_WORDS_MUST_BE_FUNCTION_OR_ARRAY');\n        case 42:\n          _context.next = 38;\n          break;\n        case 44:\n          _context.next = 49;\n          break;\n        case 46:\n          _context.prev = 46;\n          _context.t0 = _context[\"catch\"](36);\n          _iterator.e(_context.t0);\n        case 49:\n          _context.prev = 49;\n          _iterator.f();\n          return _context.finish(49);\n        case 52:\n          // Create the tokenizer\n          tokenizer = {\n            tokenize: tokenize,\n            language: config.language,\n            stemmer: stemmer,\n            stemmerSkipProperties: new Set(config.stemmerSkipProperties ? [config.stemmerSkipProperties].flat() : []),\n            stopWords: stopWords,\n            allowDuplicates: Boolean(config.allowDuplicates),\n            normalizeToken: normalizeToken,\n            normalizationCache: new Map()\n          };\n          tokenizer.tokenize = tokenize.bind(tokenizer);\n          tokenizer.normalizeToken = normalizeToken;\n          return _context.abrupt(\"return\", tokenizer);\n        case 56:\n        case \"end\":\n          return _context.stop();\n      }\n    }, _callee, null, [[36, 46, 49, 52]]);\n  }));\n  return _createTokenizer.apply(this, arguments);\n}","map":{"version":3,"names":["createError","replaceDiacritics","SPLITTERS","SUPPORTED_LANGUAGES","stopWords","defaultStopWords","stemmer","english","normalizeToken","prop","token","_this_stopWords","key","concat","language","normalizationCache","has","get","includes","set","stemmerSkipProperties","trim","text","length","pop","shift","tokenize","input","splitRule","tokens","toLowerCase","split","map","bind","filter","Boolean","trimTokens","allowDuplicates","Array","from","Set","createTokenizer","_createTokenizer","apply","arguments","_asyncToGenerator","_regeneratorRuntime","mark","_callee","config","_defaultStopWords$con","_iterator","_step","s","tokenizer","_args","wrap","_callee$","_context","prev","next","undefined","stemming","isArray","sent","_createForOfIteratorHelper","n","done","value","t0","e","f","finish","flat","Map","abrupt","stop"],"sources":["/home/krug/Coding/JavaScript/Websites/Personal/personal/node_modules/.pnpm/@orama+orama@1.0.3/node_modules/@orama/orama/src/components/tokenizer/index.ts"],"sourcesContent":["import { createError } from '../../errors.js'\nimport { Stemmer, Tokenizer, DefaultTokenizerConfig } from '../../types.js'\nimport { replaceDiacritics } from './diacritics.js'\nimport { Language, SPLITTERS, SUPPORTED_LANGUAGES } from './languages.js'\nimport { stopWords as defaultStopWords } from './stop-words/index.js'\nimport { stemmer as english } from './english-stemmer.js'\n\ninterface DefaultTokenizer extends Tokenizer {\n  language: Language\n  stemmer?: Stemmer\n  stemmerSkipProperties: Set<string>\n  stopWords?: string[]\n  allowDuplicates: boolean\n  normalizationCache: Map<string, string>\n  normalizeToken(this: DefaultTokenizer, token: string, prop: string | undefined): string\n}\n\nfunction normalizeToken(this: DefaultTokenizer, prop: string, token: string): string {\n  const key = `${this.language}:${prop}:${token}`\n\n  if (this.normalizationCache.has(key)) {\n    return this.normalizationCache.get(key)!\n  }\n\n  // Remove stopwords if enabled\n  if (this.stopWords?.includes(token)) {\n    this.normalizationCache.set(key, '')\n    return ''\n  }\n\n  // Apply stemming if enabled\n  if (this.stemmer && !this.stemmerSkipProperties.has(prop)) {\n    token = this.stemmer(token)\n  }\n\n  token = replaceDiacritics(token)\n  this.normalizationCache.set(key, token)\n  return token\n}\n\n/* c8 ignore next 10 */\nfunction trim(text: string[]): string[] {\n  while (text[text.length - 1] === '') {\n    text.pop()\n  }\n  while (text[0] === '') {\n    text.shift()\n  }\n  return text\n}\n\nfunction tokenize(this: DefaultTokenizer, input: string, language?: string, prop?: string): string[] {\n  if (language && language !== this.language) {\n    throw createError('LANGUAGE_NOT_SUPPORTED', language)\n  }\n\n  /* c8 ignore next 3 */\n  if (typeof input !== 'string') {\n    return [input]\n  }\n\n  const splitRule = SPLITTERS[this.language]\n  const tokens = input\n    .toLowerCase()\n    .split(splitRule)\n    .map(this.normalizeToken.bind(this, prop ?? ''))\n    .filter(Boolean)\n  const trimTokens = trim(tokens)\n\n  if (!this.allowDuplicates) {\n    return Array.from(new Set(trimTokens))\n  }\n\n  return trimTokens\n}\n\nexport async function createTokenizer(config: DefaultTokenizerConfig = {}): Promise<DefaultTokenizer> {\n  if (!config.language) {\n    config.language = 'english'\n  } else if (!SUPPORTED_LANGUAGES.includes(config.language)) {\n    throw createError('LANGUAGE_NOT_SUPPORTED', config.language)\n  }\n\n  // Handle stemming - It is disabled by default\n  let stemmer: Stemmer | undefined\n\n  if (config.stemming || (config.stemmer && !('stemming' in config))) {\n    if (config.stemmer) {\n      if (typeof config.stemmer !== 'function') {\n        throw createError('INVALID_STEMMER_FUNCTION_TYPE')\n      }\n\n      stemmer = config.stemmer\n    } else {\n      if (config.language === 'english') {\n        stemmer = english\n      } else {\n        throw createError('MISSING_STEMMER', config.language)\n      }\n    }\n  }\n\n  // Handle stopwords\n  let stopWords: string[] | undefined\n\n  if (config.stopWords !== false) {\n    stopWords = defaultStopWords[config.language] ?? []\n\n    if (Array.isArray(config.stopWords)) {\n      stopWords = config.stopWords\n    } else if (typeof config.stopWords === 'function') {\n      stopWords = await config.stopWords(stopWords)\n    } else if (config.stopWords) {\n      throw createError('CUSTOM_STOP_WORDS_MUST_BE_FUNCTION_OR_ARRAY')\n    }\n\n    // Make sure stopWords is just an array of strings\n    if (!Array.isArray(stopWords)) {\n      throw createError('CUSTOM_STOP_WORDS_MUST_BE_FUNCTION_OR_ARRAY')\n    }\n\n    for (const s of stopWords) {\n      if (typeof s !== 'string') {\n        throw createError('CUSTOM_STOP_WORDS_MUST_BE_FUNCTION_OR_ARRAY')\n      }\n    }\n  }\n\n  // Create the tokenizer\n  const tokenizer: DefaultTokenizer = {\n    tokenize,\n    language: config.language,\n    stemmer,\n    stemmerSkipProperties: new Set(config.stemmerSkipProperties ? [config.stemmerSkipProperties].flat() : []),\n    stopWords,\n    allowDuplicates: Boolean(config.allowDuplicates),\n    normalizeToken,\n    normalizationCache: new Map(),\n  }\n\n  tokenizer.tokenize = tokenize.bind(tokenizer)\n  tokenizer.normalizeToken = normalizeToken\n\n  return tokenizer\n}\n"],"mappings":";;;AAAA,SAASA,WAAW,QAAQ;AAE5B,SAASC,iBAAiB,QAAQ;AAClC,SAAmBC,SAAS,EAAEC,mBAAmB,QAAQ;AACzD,SAASC,SAAA,IAAaC,gBAAgB,QAAQ;AAC9C,SAASC,OAAA,IAAWC,OAAO,QAAQ;AAYnC,SAASC,eAAuCC,IAAY,EAAEC,KAAa,EAAU;MAQ/EC,eAAA;EAPJ,IAAMC,GAAA,MAAAC,MAAA,CAAS,IAAI,CAACC,QAAQ,OAAAD,MAAA,CAAIJ,IAAA,OAAAI,MAAA,CAAQH,KAAA,CAAO;EAE/C,IAAI,IAAI,CAACK,kBAAkB,CAACC,GAAG,CAACJ,GAAA,GAAM;IACpC,OAAO,IAAI,CAACG,kBAAkB,CAACE,GAAG,CAACL,GAAA;EACrC;EAEA;EACA,IAAI,CAAAD,eAAA,OAAI,CAACP,SAAS,cAAdO,eAAA,uBAAAA,eAAA,CAAgBO,QAAA,CAASR,KAAA,GAAQ;IACnC,IAAI,CAACK,kBAAkB,CAACI,GAAG,CAACP,GAAA,EAAK;IACjC,OAAO;EACT;EAEA;EACA,IAAI,IAAI,CAACN,OAAO,IAAI,CAAC,IAAI,CAACc,qBAAqB,CAACJ,GAAG,CAACP,IAAA,GAAO;IACzDC,KAAA,GAAQ,IAAI,CAACJ,OAAO,CAACI,KAAA;EACvB;EAEAA,KAAA,GAAQT,iBAAA,CAAkBS,KAAA;EAC1B,IAAI,CAACK,kBAAkB,CAACI,GAAG,CAACP,GAAA,EAAKF,KAAA;EACjC,OAAOA,KAAA;AACT;AAEA;AACA,SAASW,KAAKC,IAAc,EAAY;EACtC,OAAOA,IAAI,CAACA,IAAA,CAAKC,MAAM,GAAG,EAAE,KAAK,IAAI;IACnCD,IAAA,CAAKE,GAAG;EACV;EACA,OAAOF,IAAI,CAAC,EAAE,KAAK,IAAI;IACrBA,IAAA,CAAKG,KAAK;EACZ;EACA,OAAOH,IAAA;AACT;AAEA,SAASI,SAAiCC,KAAa,EAAEb,QAAiB,EAAEL,IAAa,EAAY;EACnG,IAAIK,QAAA,IAAYA,QAAA,KAAa,IAAI,CAACA,QAAQ,EAAE;IAC1C,MAAMd,WAAA,CAAY,0BAA0Bc,QAAA;EAC9C;EAEA;EACA,IAAI,OAAOa,KAAA,KAAU,UAAU;IAC7B,OAAO,CAACA,KAAA,CAAM;EAChB;EAEA,IAAMC,SAAA,GAAY1B,SAAS,CAAC,IAAI,CAACY,QAAQ,CAAC;EAC1C,IAAMe,MAAA,GAASF,KAAA,CACZG,WAAW,GACXC,KAAK,CAACH,SAAA,EACNI,GAAG,CAAC,IAAI,CAACxB,cAAc,CAACyB,IAAI,CAAC,IAAI,EAAExB,IAAA,aAAAA,IAAA,cAAAA,IAAA,GAAQ,KAC3CyB,MAAM,CAACC,OAAA;EACV,IAAMC,UAAA,GAAaf,IAAA,CAAKQ,MAAA;EAExB,IAAI,CAAC,IAAI,CAACQ,eAAe,EAAE;IACzB,OAAOC,KAAA,CAAMC,IAAI,CAAC,IAAIC,GAAA,CAAIJ,UAAA;EAC5B;EAEA,OAAOA,UAAA;AACT;AAEA,gBAAsBK,gBAAA;EAAA,OAAAC,gBAAA,CAAAC,KAAA,OAAAC,SAAA;AAAA;AAoErB,SAAAF,iBAAA;EAAAA,gBAAA,GAAAG,iBAAA,eAAAC,mBAAA,GAAAC,IAAA,CApEM,SAAAC,QAAA;IAAA,IAAAC,MAAA;MAAA3C,OAAA;MAAAF,SAAA;MAAA8C,qBAAA;MAAAC,SAAA;MAAAC,KAAA;MAAAC,CAAA;MAAAC,SAAA;MAAAC,KAAA,GAAAX,SAAA;IAAA,OAAAE,mBAAA,GAAAU,IAAA,UAAAC,SAAAC,QAAA;MAAA,kBAAAA,QAAA,CAAAC,IAAA,GAAAD,QAAA,CAAAE,IAAA;QAAA;UAA+BX,MAAA,GAAAM,KAAA,CAAAhC,MAAA,QAAAgC,KAAA,QAAAM,SAAA,GAAAN,KAAA,MAAiC,CAAC,CAAC;UAAA,IAClEN,MAAA,CAAOnC,QAAQ;YAAA4C,QAAA,CAAAE,IAAA;YAAA;UAAA;UAClBX,MAAA,CAAOnC,QAAQ,GAAG;UAAA4C,QAAA,CAAAE,IAAA;UAAA;QAAA;UAAA,IACRzD,mBAAA,CAAoBe,QAAQ,CAAC+B,MAAA,CAAOnC,QAAQ;YAAA4C,QAAA,CAAAE,IAAA;YAAA;UAAA;UAAA,MAChD5D,WAAA,CAAY,0BAA0BiD,MAAA,CAAOnC,QAAQ;QAAA;UAAA,MAMzDmC,MAAA,CAAOa,QAAQ,IAAKb,MAAA,CAAO3C,OAAO,IAAI,EAAE,cAAc2C,MAAK;YAAAS,QAAA,CAAAE,IAAA;YAAA;UAAA;UAAA,KACzDX,MAAA,CAAO3C,OAAO;YAAAoD,QAAA,CAAAE,IAAA;YAAA;UAAA;UAAA,MACZ,OAAOX,MAAA,CAAO3C,OAAO,KAAK;YAAAoD,QAAA,CAAAE,IAAA;YAAA;UAAA;UAAA,MACtB5D,WAAA,CAAY;QAAA;UAGpBM,OAAA,GAAU2C,MAAA,CAAO3C,OAAO;UAAAoD,QAAA,CAAAE,IAAA;UAAA;QAAA;UAAA,MAEpBX,MAAA,CAAOnC,QAAQ,KAAK;YAAA4C,QAAA,CAAAE,IAAA;YAAA;UAAA;UACtBtD,OAAA,GAAUC,OAAA;UAAAmD,QAAA,CAAAE,IAAA;UAAA;QAAA;UAAA,MAEJ5D,WAAA,CAAY,mBAAmBiD,MAAA,CAAOnC,QAAQ;QAAA;UAAA,MAQtDmC,MAAA,CAAO7C,SAAS,KAAK,KAAK;YAAAsD,QAAA,CAAAE,IAAA;YAAA;UAAA;UAC5BxD,SAAA,IAAA8C,qBAAA,GAAY7C,gBAAgB,CAAC4C,MAAA,CAAOnC,QAAQ,CAAC,cAAAoC,qBAAA,cAAAA,qBAAA,GAAI,EAAE;UAAA,KAE/CZ,KAAA,CAAMyB,OAAO,CAACd,MAAA,CAAO7C,SAAS;YAAAsD,QAAA,CAAAE,IAAA;YAAA;UAAA;UAChCxD,SAAA,GAAY6C,MAAA,CAAO7C,SAAS;UAAAsD,QAAA,CAAAE,IAAA;UAAA;QAAA;UAAA,MACnB,OAAOX,MAAA,CAAO7C,SAAS,KAAK;YAAAsD,QAAA,CAAAE,IAAA;YAAA;UAAA;UAAAF,QAAA,CAAAE,IAAA;UAAA,OACnBX,MAAA,CAAO7C,SAAS,CAACA,SAAA;QAAA;UAAnCA,SAAA,GAAAsD,QAAA,CAAAM,IAAA;UAAAN,QAAA,CAAAE,IAAA;UAAA;QAAA;UAAA,KACSX,MAAA,CAAO7C,SAAS;YAAAsD,QAAA,CAAAE,IAAA;YAAA;UAAA;UAAA,MACnB5D,WAAA,CAAY;QAAA;UAAA,IAIfsC,KAAA,CAAMyB,OAAO,CAAC3D,SAAA;YAAAsD,QAAA,CAAAE,IAAA;YAAA;UAAA;UAAA,MACX5D,WAAA,CAAY;QAAA;UAAAmD,SAAA,GAAAc,0BAAA,CAGJ7D,SAAA;UAAAsD,QAAA,CAAAC,IAAA;UAAAR,SAAA,CAAAE,CAAA;QAAA;UAAA,KAAAD,KAAA,GAAAD,SAAA,CAAAe,CAAA,IAAAC,IAAA;YAAAT,QAAA,CAAAE,IAAA;YAAA;UAAA;UAALP,CAAA,GAAAD,KAAA,CAAAgB,KAAA;UAAA,MACL,OAAOf,CAAA,KAAM;YAAAK,QAAA,CAAAE,IAAA;YAAA;UAAA;UAAA,MACT5D,WAAA,CAAY;QAAA;UAAA0D,QAAA,CAAAE,IAAA;UAAA;QAAA;UAAAF,QAAA,CAAAE,IAAA;UAAA;QAAA;UAAAF,QAAA,CAAAC,IAAA;UAAAD,QAAA,CAAAW,EAAA,GAAAX,QAAA;UAAAP,SAAA,CAAAmB,CAAA,CAAAZ,QAAA,CAAAW,EAAA;QAAA;UAAAX,QAAA,CAAAC,IAAA;UAAAR,SAAA,CAAAoB,CAAA;UAAA,OAAAb,QAAA,CAAAc,MAAA;QAAA;UAKxB;UACMlB,SAAA,GAA8B;YAClC5B,QAAA,EAAAA,QAAA;YACAZ,QAAA,EAAUmC,MAAA,CAAOnC,QAAQ;YACzBR,OAAA,EAAAA,OAAA;YACAc,qBAAA,EAAuB,IAAIoB,GAAA,CAAIS,MAAA,CAAO7B,qBAAqB,GAAG,CAAC6B,MAAA,CAAO7B,qBAAqB,CAAC,CAACqD,IAAI,KAAK,EAAE;YACxGrE,SAAA,EAAAA,SAAA;YACAiC,eAAA,EAAiBF,OAAA,CAAQc,MAAA,CAAOZ,eAAe;YAC/C7B,cAAA,EAAAA,cAAA;YACAO,kBAAA,EAAoB,IAAI2D,GAAA;UAC1B;UAEApB,SAAA,CAAU5B,QAAQ,GAAGA,QAAA,CAASO,IAAI,CAACqB,SAAA;UACnCA,SAAA,CAAU9C,cAAc,GAAGA,cAAA;UAAA,OAAAkD,QAAA,CAAAiB,MAAA,WAEpBrB,SAAA;QAAA;QAAA;UAAA,OAAAI,QAAA,CAAAkB,IAAA;MAAA;IAAA,GAAA5B,OAAA;EAAA,CACR;EAAA,OAAAN,gBAAA,CAAAC,KAAA,OAAAC,SAAA;AAAA"},"metadata":{},"sourceType":"module","externalDependencies":[]}