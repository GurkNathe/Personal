{"ast":null,"code":"import { prioritizeTokenScores } from '../components/algorithms.js';\nimport { getFacets } from '../components/facets.js';\nimport { intersectFilteredIDs } from '../components/filters.js';\nimport { getGroups } from '../components/groups.js';\nimport { runAfterSearch } from '../components/hooks.js';\nimport { getDocumentIdFromInternalId, getInternalDocumentId } from '../components/internal-document-id-store.js';\nimport { createError } from '../errors.js';\nimport { getNanosecondsTime, getNested, sortTokenScorePredicate, safeArrayPush } from '../utils.js';\nconst defaultBM25Params = {\n  k: 1.2,\n  b: 0.75,\n  d: 0.5\n};\nasync function createSearchContext(tokenizer, index, documentsStore, language, params, properties, tokens, docsCount, timeStart) {\n  // If filters are enabled, we need to get the IDs of the documents that match the filters.\n  // const hasFilters = Object.keys(params.where ?? {}).length > 0;\n  // let whereFiltersIDs: string[] = [];\n  // if (hasFilters) {\n  //   whereFiltersIDs = getWhereFiltersIDs(params.where!, orama);\n  // }\n  // indexMap is an object containing all the indexes considered for the current search,\n  // and an array of doc IDs for each token in all the indices.\n  //\n  // Given the search term \"quick brown fox\" on the \"description\" index,\n  // indexMap will look like this:\n  //\n  // {\n  //   description: {\n  //     quick: [doc1, doc2, doc3],\n  //     brown: [doc2, doc4],\n  //     fox:   [doc2]\n  //   }\n  // }\n  const indexMap = {};\n  // After we create the indexMap, we need to calculate the intersection\n  // between all the postings lists for each token.\n  // Given the example above, docsIntersection will look like this:\n  //\n  // {\n  //   description: [doc2]\n  // }\n  //\n  // as doc2 is the only document present in all the postings lists for the \"description\" index.\n  const docsIntersection = {};\n  for (const prop of properties) {\n    const tokensMap = {};\n    for (const token of tokens) {\n      tokensMap[token] = [];\n    }\n    indexMap[prop] = tokensMap;\n    docsIntersection[prop] = [];\n  }\n  return {\n    timeStart,\n    tokenizer,\n    index,\n    documentsStore,\n    language,\n    params,\n    docsCount,\n    uniqueDocsIDs: {},\n    indexMap,\n    docsIntersection\n  };\n}\nexport async function search(orama, params, language) {\n  var _params$relevance, _params$where;\n  const timeStart = await getNanosecondsTime();\n  params.relevance = Object.assign((_params$relevance = params.relevance) !== null && _params$relevance !== void 0 ? _params$relevance : {}, defaultBM25Params);\n  const shouldCalculateFacets = params.facets && Object.keys(params.facets).length > 0;\n  const {\n    limit = 10,\n    offset = 0,\n    term,\n    properties,\n    threshold = 1,\n    distinctOn\n  } = params;\n  const isPreflight = params.preflight === true;\n  const {\n    index,\n    docs\n  } = orama.data;\n  const tokens = await orama.tokenizer.tokenize(term !== null && term !== void 0 ? term : '', language);\n  // Get searchable string properties\n  let propertiesToSearch = orama.caches['propertiesToSearch'];\n  if (!propertiesToSearch) {\n    const propertiesToSearchWithTypes = await orama.index.getSearchablePropertiesWithTypes(index);\n    propertiesToSearch = await orama.index.getSearchableProperties(index);\n    propertiesToSearch = propertiesToSearch.filter(prop => propertiesToSearchWithTypes[prop].startsWith('string'));\n    orama.caches['propertiesToSearch'] = propertiesToSearch;\n  }\n  if (properties && properties !== '*') {\n    for (const prop of properties) {\n      if (!propertiesToSearch.includes(prop)) {\n        throw createError('UNKNOWN_INDEX', prop, propertiesToSearch.join(', '));\n      }\n    }\n    propertiesToSearch = propertiesToSearch.filter(prop => properties.includes(prop));\n  }\n  // Create the search context and the results\n  const context = await createSearchContext(orama.tokenizer, orama.index, orama.documentsStore, language, params, propertiesToSearch, tokens, await orama.documentsStore.count(docs), timeStart);\n  // If filters are enabled, we need to get the IDs of the documents that match the filters.\n  const hasFilters = Object.keys((_params$where = params.where) !== null && _params$where !== void 0 ? _params$where : {}).length > 0;\n  let whereFiltersIDs = [];\n  if (hasFilters) {\n    whereFiltersIDs = await orama.index.searchByWhereClause(context, index, params.where);\n  }\n  const tokensLength = tokens.length;\n  if (tokensLength || properties && properties.length > 0) {\n    // Now it's time to loop over all the indices and get the documents IDs for every single term\n    const indexesLength = propertiesToSearch.length;\n    for (let i = 0; i < indexesLength; i++) {\n      var _ref;\n      var _params_boost;\n      const prop = propertiesToSearch[i];\n      if (tokensLength !== 0) {\n        for (let j = 0; j < tokensLength; j++) {\n          const term = tokens[j];\n          // Lookup\n          const scoreList = await orama.index.search(context, index, prop, term);\n          safeArrayPush(context.indexMap[prop][term], scoreList);\n        }\n      } else {\n        context.indexMap[prop][''] = [];\n        const scoreList = await orama.index.search(context, index, prop, '');\n        safeArrayPush(context.indexMap[prop][''], scoreList);\n      }\n      const docIds = context.indexMap[prop];\n      const vals = Object.values(docIds);\n      context.docsIntersection[prop] = prioritizeTokenScores(vals, (_ref = params === null || params === void 0 ? void 0 : (_params_boost = params.boost) === null || _params_boost === void 0 ? void 0 : _params_boost[prop]) !== null && _ref !== void 0 ? _ref : 1, threshold, tokensLength);\n      const uniqueDocs = context.docsIntersection[prop];\n      const uniqueDocsLength = uniqueDocs.length;\n      for (let i = 0; i < uniqueDocsLength; i++) {\n        const [id, score] = uniqueDocs[i];\n        const prevScore = context.uniqueDocsIDs[id];\n        if (prevScore) {\n          context.uniqueDocsIDs[id] = prevScore + score + 0.5;\n        } else {\n          context.uniqueDocsIDs[id] = score;\n        }\n      }\n    }\n  } else if (tokens.length === 0 && term) {\n    // This case is hard to handle correctly.\n    // For the time being, if tokenizer returns empty array but the term is not empty,\n    // we returns an empty result set\n    context.uniqueDocsIDs = {};\n  } else {\n    context.uniqueDocsIDs = Object.fromEntries(Object.keys(await orama.documentsStore.getAll(orama.data.docs)).map(k => [k, 0]));\n  }\n  // Get unique doc IDs from uniqueDocsIDs map\n  let uniqueDocsArray = Object.entries(context.uniqueDocsIDs).map(_ref2 => {\n    let [id, score] = _ref2;\n    return [+id, score];\n  });\n  // If filters are enabled, we need to remove the IDs of the documents that don't match the filters.\n  if (hasFilters) {\n    uniqueDocsArray = intersectFilteredIDs(whereFiltersIDs, uniqueDocsArray);\n  }\n  if (params.sortBy) {\n    if (typeof params.sortBy === 'function') {\n      const ids = uniqueDocsArray.map(_ref3 => {\n        let [id] = _ref3;\n        return id;\n      });\n      const docs = await orama.documentsStore.getMultiple(orama.data.docs, ids);\n      const docsWithIdAndScore = docs.map((d, i) => [uniqueDocsArray[i][0], uniqueDocsArray[i][1], d]);\n      docsWithIdAndScore.sort(params.sortBy);\n      uniqueDocsArray = docsWithIdAndScore.map(_ref4 => {\n        let [id, score] = _ref4;\n        return [id, score];\n      });\n    } else {\n      uniqueDocsArray = await orama.sorter.sortBy(orama.data.sorting, uniqueDocsArray, params.sortBy).then(results => results.map(_ref5 => {\n        let [id, score] = _ref5;\n        return [getInternalDocumentId(orama.internalDocumentIDStore, id), score];\n      }));\n    }\n  } else {\n    uniqueDocsArray = uniqueDocsArray.sort(sortTokenScorePredicate);\n  }\n  let results;\n  if (!isPreflight && distinctOn) {\n    results = await fetchDocumentsWithDistinct(orama, uniqueDocsArray, offset, limit, distinctOn);\n  } else if (!isPreflight) {\n    results = await fetchDocuments(orama, uniqueDocsArray, offset, limit);\n  }\n  const searchResult = {\n    elapsed: {\n      formatted: '',\n      raw: 0\n    },\n    // We keep the hits array empty if it's a preflight request.\n    hits: [],\n    count: uniqueDocsArray.length\n  };\n  if (typeof results !== 'undefined') {\n    searchResult.hits = results.filter(Boolean);\n  }\n  if (shouldCalculateFacets) {\n    // Populate facets if needed\n    const facets = await getFacets(orama, uniqueDocsArray, params.facets);\n    searchResult.facets = facets;\n  }\n  if (params.groupBy) {\n    searchResult.groups = await getGroups(orama, uniqueDocsArray, params.groupBy);\n  }\n  if (orama.afterSearch) {\n    await runAfterSearch(orama.afterSearch, orama, params, language, searchResult);\n  }\n  // Calculate elapsed time only at the end of the function\n  searchResult.elapsed = await orama.formatElapsedTime((await getNanosecondsTime()) - context.timeStart);\n  return searchResult;\n}\nasync function fetchDocumentsWithDistinct(orama, uniqueDocsArray, offset, limit, distinctOn) {\n  const docs = orama.data.docs;\n  // Keep track which values we already seen\n  const values = new Map();\n  // We cannot know how many results we will have in the end,\n  // so we need cannot pre-allocate the array.\n  const results = [];\n  const resultIDs = new Set();\n  const uniqueDocsArrayLength = uniqueDocsArray.length;\n  let count = 0;\n  for (let i = 0; i < uniqueDocsArrayLength; i++) {\n    const idAndScore = uniqueDocsArray[i];\n    // If there are no more results, just break the loop\n    if (typeof idAndScore === 'undefined') {\n      continue;\n    }\n    const [id, score] = idAndScore;\n    if (resultIDs.has(id)) {\n      continue;\n    }\n    const doc = await orama.documentsStore.get(docs, id);\n    const value = await getNested(doc, distinctOn);\n    if (typeof value === 'undefined' || values.has(value)) {\n      continue;\n    }\n    values.set(value, true);\n    count++;\n    // We shouldn't consider the document if it's not in the offset range\n    if (count <= offset) {\n      continue;\n    }\n    results.push({\n      id: getDocumentIdFromInternalId(orama.internalDocumentIDStore, id),\n      score,\n      document: doc\n    });\n    resultIDs.add(id);\n    // reached the limit, break the loop\n    if (count >= offset + limit) {\n      break;\n    }\n  }\n  return results;\n}\nasync function fetchDocuments(orama, uniqueDocsArray, offset, limit) {\n  const docs = orama.data.docs;\n  const results = Array.from({\n    length: limit\n  });\n  const resultIDs = new Set();\n  // We already have the list of ALL the document IDs containing the search terms.\n  // We loop over them starting from a positional value \"offset\" and ending at \"offset + limit\"\n  // to provide pagination capabilities to the search.\n  for (let i = offset; i < limit + offset; i++) {\n    const idAndScore = uniqueDocsArray[i];\n    // If there are no more results, just break the loop\n    if (typeof idAndScore === 'undefined') {\n      break;\n    }\n    const [id, score] = idAndScore;\n    if (!resultIDs.has(id)) {\n      // We retrieve the full document only AFTER making sure that we really want it.\n      // We never retrieve the full document preventively.\n      const fullDoc = await orama.documentsStore.get(docs, id);\n      results[i] = {\n        id: getDocumentIdFromInternalId(orama.internalDocumentIDStore, id),\n        score,\n        document: fullDoc\n      };\n      resultIDs.add(id);\n    }\n  }\n  return results;\n}","map":{"version":3,"names":["prioritizeTokenScores","getFacets","intersectFilteredIDs","getGroups","runAfterSearch","getDocumentIdFromInternalId","getInternalDocumentId","createError","getNanosecondsTime","getNested","sortTokenScorePredicate","safeArrayPush","defaultBM25Params","k","b","d","createSearchContext","tokenizer","index","documentsStore","language","params","properties","tokens","docsCount","timeStart","indexMap","docsIntersection","prop","tokensMap","token","uniqueDocsIDs","search","orama","_params$relevance","_params$where","relevance","Object","assign","shouldCalculateFacets","facets","keys","length","limit","offset","term","threshold","distinctOn","isPreflight","preflight","docs","data","tokenize","propertiesToSearch","caches","propertiesToSearchWithTypes","getSearchablePropertiesWithTypes","getSearchableProperties","filter","startsWith","includes","join","context","count","hasFilters","where","whereFiltersIDs","searchByWhereClause","tokensLength","indexesLength","i","_ref","_params_boost","j","scoreList","docIds","vals","values","boost","uniqueDocs","uniqueDocsLength","id","score","prevScore","fromEntries","getAll","map","uniqueDocsArray","entries","_ref2","sortBy","ids","_ref3","getMultiple","docsWithIdAndScore","sort","_ref4","sorter","sorting","then","results","_ref5","internalDocumentIDStore","fetchDocumentsWithDistinct","fetchDocuments","searchResult","elapsed","formatted","raw","hits","Boolean","groupBy","groups","afterSearch","formatElapsedTime","Map","resultIDs","Set","uniqueDocsArrayLength","idAndScore","has","doc","get","value","set","push","document","add","Array","from","fullDoc"],"sources":["/home/krug/Coding/JavaScript/Websites/Personal/personal/node_modules/.pnpm/@orama+orama@1.2.11/node_modules/@orama/orama/src/methods/search.ts"],"sourcesContent":["import { prioritizeTokenScores } from '../components/algorithms.js'\nimport { getFacets } from '../components/facets.js'\nimport { intersectFilteredIDs } from '../components/filters.js'\nimport { getGroups } from '../components/groups.js'\nimport { runAfterSearch } from '../components/hooks.js'\nimport {\n  InternalDocumentID,\n  getDocumentIdFromInternalId,\n  getInternalDocumentId,\n} from '../components/internal-document-id-store.js'\nimport { createError } from '../errors.js'\nimport { getNanosecondsTime, getNested, sortTokenScorePredicate, safeArrayPush } from '../utils.js';\nimport type {\n  AnyOrama,\n  BM25Params,\n  CustomSorterFunctionItem,\n  ElapsedTime,\n  IndexMap,\n  LiteralUnion,\n  Result,\n  Results,\n  SearchContext,\n  SearchParams,\n  SearchableValue,\n  TokenMap,\n  TokenScore,\n  Tokenizer,\n  TypedDocument,\n} from '../types.js'\n\nconst defaultBM25Params: BM25Params = {\n  k: 1.2,\n  b: 0.75,\n  d: 0.5,\n}\n\nasync function createSearchContext<T extends AnyOrama, ResultDocument = TypedDocument<T>>(\n  tokenizer: Tokenizer,\n  index: T['index'],\n  documentsStore: T['documentsStore'],\n  language: string | undefined,\n  params: SearchParams<T, ResultDocument>,\n  properties: string[],\n  tokens: string[],\n  docsCount: number,\n  timeStart: bigint,\n): Promise<SearchContext<T, ResultDocument>> {\n  // If filters are enabled, we need to get the IDs of the documents that match the filters.\n  // const hasFilters = Object.keys(params.where ?? {}).length > 0;\n  // let whereFiltersIDs: string[] = [];\n\n  // if (hasFilters) {\n  //   whereFiltersIDs = getWhereFiltersIDs(params.where!, orama);\n  // }\n\n  // indexMap is an object containing all the indexes considered for the current search,\n  // and an array of doc IDs for each token in all the indices.\n  //\n  // Given the search term \"quick brown fox\" on the \"description\" index,\n  // indexMap will look like this:\n  //\n  // {\n  //   description: {\n  //     quick: [doc1, doc2, doc3],\n  //     brown: [doc2, doc4],\n  //     fox:   [doc2]\n  //   }\n  // }\n  const indexMap: IndexMap = {}\n\n  // After we create the indexMap, we need to calculate the intersection\n  // between all the postings lists for each token.\n  // Given the example above, docsIntersection will look like this:\n  //\n  // {\n  //   description: [doc2]\n  // }\n  //\n  // as doc2 is the only document present in all the postings lists for the \"description\" index.\n  const docsIntersection: TokenMap = {}\n\n  for (const prop of properties) {\n    const tokensMap: TokenMap = {}\n    for (const token of tokens) {\n      tokensMap[token] = []\n    }\n    indexMap[prop] = tokensMap\n    docsIntersection[prop] = []\n  }\n\n  return {\n    timeStart,\n    tokenizer,\n    index,\n    documentsStore,\n    language,\n    params,\n    docsCount,\n    uniqueDocsIDs: {},\n    indexMap,\n    docsIntersection,\n  }\n}\n\nexport async function search<T extends AnyOrama, ResultDocument = TypedDocument<T>>(\n  orama: T,\n  params: SearchParams<T, ResultDocument>,\n  language?: string,\n): Promise<Results<ResultDocument>> {\n  const timeStart = await getNanosecondsTime()\n\n  params.relevance = Object.assign(params.relevance ?? {}, defaultBM25Params)\n\n  const shouldCalculateFacets = params.facets && Object.keys(params.facets).length > 0\n  const { limit = 10, offset = 0, term, properties, threshold = 1, distinctOn } = params\n  const isPreflight = params.preflight === true\n\n  const { index, docs } = orama.data\n  const tokens = await orama.tokenizer.tokenize(term ?? '', language)\n\n  // Get searchable string properties\n  let propertiesToSearch = orama.caches['propertiesToSearch'] as string[]\n  if (!propertiesToSearch) {\n    const propertiesToSearchWithTypes = await orama.index.getSearchablePropertiesWithTypes(index)\n\n    propertiesToSearch = await orama.index.getSearchableProperties(index)\n    propertiesToSearch = propertiesToSearch.filter((prop: string) =>\n      propertiesToSearchWithTypes[prop].startsWith('string'),\n    )\n\n    orama.caches['propertiesToSearch'] = propertiesToSearch\n  }\n\n  if (properties && properties !== '*') {\n    for (const prop of properties) {\n      if (!propertiesToSearch.includes(prop as string)) {\n        throw createError('UNKNOWN_INDEX', prop as string, propertiesToSearch.join(', '))\n      }\n    }\n\n    propertiesToSearch = propertiesToSearch.filter((prop: string) => (properties as string[]).includes(prop))\n  }\n\n  // Create the search context and the results\n  const context = await createSearchContext(\n    orama.tokenizer,\n    orama.index,\n    orama.documentsStore,\n    language,\n    params,\n    propertiesToSearch,\n    tokens,\n    await orama.documentsStore.count(docs),\n    timeStart,\n  )\n\n  // If filters are enabled, we need to get the IDs of the documents that match the filters.\n  const hasFilters = Object.keys(params.where ?? {}).length > 0\n  let whereFiltersIDs: InternalDocumentID[] = []\n\n  if (hasFilters) {\n    whereFiltersIDs = await orama.index.searchByWhereClause(context, index, params.where!)\n  }\n\n  const tokensLength = tokens.length\n\n  if (tokensLength || (properties && properties.length > 0)) {\n    // Now it's time to loop over all the indices and get the documents IDs for every single term\n    const indexesLength = propertiesToSearch.length\n    for (let i = 0; i < indexesLength; i++) {\n      const prop = propertiesToSearch[i]\n\n      if (tokensLength !== 0) {\n        for (let j = 0; j < tokensLength; j++) {\n          const term = tokens[j]\n\n          // Lookup\n          const scoreList = await orama.index.search(context, index, prop, term)\n\n          safeArrayPush(context.indexMap[prop][term], scoreList);\n        }\n      } else {\n        context.indexMap[prop][''] = []\n        const scoreList = await orama.index.search(context, index, prop, '')\n        safeArrayPush(context.indexMap[prop][''], scoreList);\n      }\n\n      const docIds = context.indexMap[prop]\n      const vals = Object.values(docIds)\n      context.docsIntersection[prop] = prioritizeTokenScores(vals, params?.boost?.[prop] ?? 1, threshold, tokensLength)\n      const uniqueDocs = context.docsIntersection[prop]\n\n      const uniqueDocsLength = uniqueDocs.length\n      for (let i = 0; i < uniqueDocsLength; i++) {\n        const [id, score] = uniqueDocs[i]\n        const prevScore = context.uniqueDocsIDs[id]\n        if (prevScore) {\n          context.uniqueDocsIDs[id] = prevScore + score + 0.5\n        } else {\n          context.uniqueDocsIDs[id] = score\n        }\n      }\n    }\n  } else if (tokens.length === 0 && term) {\n    // This case is hard to handle correctly.\n    // For the time being, if tokenizer returns empty array but the term is not empty,\n    // we returns an empty result set\n    context.uniqueDocsIDs = {}\n  } else {\n    context.uniqueDocsIDs = Object.fromEntries(\n      Object.keys(await orama.documentsStore.getAll(orama.data.docs)).map(k => [k, 0]),\n    )\n  }\n\n  // Get unique doc IDs from uniqueDocsIDs map\n  let uniqueDocsArray = Object.entries(context.uniqueDocsIDs).map(([id, score]) => [+id, score] as TokenScore)\n\n  // If filters are enabled, we need to remove the IDs of the documents that don't match the filters.\n  if (hasFilters) {\n    uniqueDocsArray = intersectFilteredIDs(whereFiltersIDs, uniqueDocsArray)\n  }\n\n  if (params.sortBy) {\n    if (typeof params.sortBy === 'function') {\n      const ids = uniqueDocsArray.map(([id]) => id)\n      const docs = await orama.documentsStore.getMultiple(orama.data.docs, ids)\n      const docsWithIdAndScore: CustomSorterFunctionItem<ResultDocument>[] = docs.map((d, i) => [\n        uniqueDocsArray[i][0],\n        uniqueDocsArray[i][1],\n        d!,\n      ])\n      docsWithIdAndScore.sort(params.sortBy)\n      uniqueDocsArray = docsWithIdAndScore.map(([id, score]) => [id, score])\n    } else {\n      uniqueDocsArray = await orama.sorter\n        .sortBy(orama.data.sorting, uniqueDocsArray, params.sortBy)\n        .then(results =>\n          results.map(([id, score]) => [getInternalDocumentId(orama.internalDocumentIDStore, id), score]),\n        )\n    }\n  } else {\n    uniqueDocsArray = uniqueDocsArray.sort(sortTokenScorePredicate)\n  }\n\n  let results\n  if (!isPreflight && distinctOn) {\n    results = await fetchDocumentsWithDistinct(orama, uniqueDocsArray, offset, limit, distinctOn)\n  } else if (!isPreflight) {\n    results = await fetchDocuments(orama, uniqueDocsArray, offset, limit)\n  }\n\n  const searchResult: Results<ResultDocument> = {\n    elapsed: {\n      formatted: '',\n      raw: 0,\n    },\n    // We keep the hits array empty if it's a preflight request.\n    hits: [],\n    count: uniqueDocsArray.length,\n  }\n\n  if (typeof results !== 'undefined') {\n    searchResult.hits = results.filter(Boolean)\n  }\n\n  if (shouldCalculateFacets) {\n    // Populate facets if needed\n    const facets = await getFacets(orama, uniqueDocsArray, params.facets!)\n    searchResult.facets = facets\n  }\n\n  if (params.groupBy) {\n    searchResult.groups = await getGroups<T, ResultDocument>(orama, uniqueDocsArray, params.groupBy)\n  }\n\n  if (orama.afterSearch) {\n    await runAfterSearch(orama.afterSearch, orama, params, language, searchResult)\n  }\n\n  // Calculate elapsed time only at the end of the function\n  searchResult.elapsed = (await orama.formatElapsedTime(\n    (await getNanosecondsTime()) - context.timeStart,\n  )) as ElapsedTime\n\n  return searchResult\n}\n\nasync function fetchDocumentsWithDistinct<T extends AnyOrama, ResultDocument extends TypedDocument<T>>(\n  orama: T,\n  uniqueDocsArray: [InternalDocumentID, number][],\n  offset: number,\n  limit: number,\n  distinctOn: LiteralUnion<T['schema']>,\n): Promise<Result<ResultDocument>[]> {\n  const docs = orama.data.docs\n\n  // Keep track which values we already seen\n  const values = new Map<SearchableValue, true>()\n\n  // We cannot know how many results we will have in the end,\n  // so we need cannot pre-allocate the array.\n  const results: Result<ResultDocument>[] = []\n\n  const resultIDs: Set<InternalDocumentID> = new Set()\n  const uniqueDocsArrayLength = uniqueDocsArray.length\n  let count = 0\n  for (let i = 0; i < uniqueDocsArrayLength; i++) {\n    const idAndScore = uniqueDocsArray[i]\n\n    // If there are no more results, just break the loop\n    if (typeof idAndScore === 'undefined') {\n      continue\n    }\n\n    const [id, score] = idAndScore\n\n    if (resultIDs.has(id)) {\n      continue\n    }\n\n    const doc = await orama.documentsStore.get(docs, id)\n    const value = await getNested(doc as object, distinctOn)\n    if (typeof value === 'undefined' || values.has(value)) {\n      continue\n    }\n    values.set(value, true)\n\n    count++\n    // We shouldn't consider the document if it's not in the offset range\n    if (count <= offset) {\n      continue\n    }\n\n    results.push({ id: getDocumentIdFromInternalId(orama.internalDocumentIDStore, id), score, document: doc! })\n    resultIDs.add(id)\n\n    // reached the limit, break the loop\n    if (count >= offset + limit) {\n      break\n    }\n  }\n\n  return results\n}\n\nasync function fetchDocuments<T extends AnyOrama, ResultDocument extends TypedDocument<T>>(\n  orama: T,\n  uniqueDocsArray: [InternalDocumentID, number][],\n  offset: number,\n  limit: number,\n): Promise<Result<ResultDocument>[]> {\n  const docs = orama.data.docs\n\n  const results: Result<ResultDocument>[] = Array.from({\n    length: limit,\n  })\n\n  const resultIDs: Set<InternalDocumentID> = new Set()\n\n  // We already have the list of ALL the document IDs containing the search terms.\n  // We loop over them starting from a positional value \"offset\" and ending at \"offset + limit\"\n  // to provide pagination capabilities to the search.\n  for (let i = offset; i < limit + offset; i++) {\n    const idAndScore = uniqueDocsArray[i]\n\n    // If there are no more results, just break the loop\n    if (typeof idAndScore === 'undefined') {\n      break\n    }\n\n    const [id, score] = idAndScore\n\n    if (!resultIDs.has(id)) {\n      // We retrieve the full document only AFTER making sure that we really want it.\n      // We never retrieve the full document preventively.\n      const fullDoc = await orama.documentsStore.get(docs, id)\n      results[i] = { id: getDocumentIdFromInternalId(orama.internalDocumentIDStore, id), score, document: fullDoc! }\n      resultIDs.add(id)\n    }\n  }\n  return results\n}\n"],"mappings":"AAAA,SAASA,qBAAqB,QAAQ;AACtC,SAASC,SAAS,QAAQ;AAC1B,SAASC,oBAAoB,QAAQ;AACrC,SAASC,SAAS,QAAQ;AAC1B,SAASC,cAAc,QAAQ;AAC/B,SAEEC,2BAA2B,EAC3BC,qBAAqB,QAChB;AACP,SAASC,WAAW,QAAQ;AAC5B,SAASC,kBAAkB,EAAEC,SAAS,EAAEC,uBAAuB,EAAEC,aAAa,QAAQ;AAmBtF,MAAMC,iBAAA,GAAgC;EACpCC,CAAA,EAAG;EACHC,CAAA,EAAG;EACHC,CAAA,EAAG;AACL;AAEA,eAAeC,oBACbC,SAAoB,EACpBC,KAAiB,EACjBC,cAAmC,EACnCC,QAA4B,EAC5BC,MAAuC,EACvCC,UAAoB,EACpBC,MAAgB,EAChBC,SAAiB,EACjBC,SAAiB,EAC0B;EAC3C;EACA;EACA;EAEA;EACA;EACA;EAEA;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EACA,MAAMC,QAAA,GAAqB,CAAC;EAE5B;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EACA,MAAMC,gBAAA,GAA6B,CAAC;EAEpC,KAAK,MAAMC,IAAA,IAAQN,UAAA,EAAY;IAC7B,MAAMO,SAAA,GAAsB,CAAC;IAC7B,KAAK,MAAMC,KAAA,IAASP,MAAA,EAAQ;MAC1BM,SAAS,CAACC,KAAA,CAAM,GAAG,EAAE;IACvB;IACAJ,QAAQ,CAACE,IAAA,CAAK,GAAGC,SAAA;IACjBF,gBAAgB,CAACC,IAAA,CAAK,GAAG,EAAE;EAC7B;EAEA,OAAO;IACLH,SAAA;IACAR,SAAA;IACAC,KAAA;IACAC,cAAA;IACAC,QAAA;IACAC,MAAA;IACAG,SAAA;IACAO,aAAA,EAAe,CAAC;IAChBL,QAAA;IACAC;EACF;AACF;AAEA,OAAO,eAAeK,OACpBC,KAAQ,EACRZ,MAAuC,EACvCD,QAAiB,EACiB;EAAA,IAAAc,iBAAA,EAAAC,aAAA;EAClC,MAAMV,SAAA,GAAY,MAAMjB,kBAAA;EAExBa,MAAA,CAAOe,SAAS,GAAGC,MAAA,CAAOC,MAAM,EAAAJ,iBAAA,GAACb,MAAA,CAAOe,SAAS,cAAAF,iBAAA,cAAAA,iBAAA,GAAI,CAAC,GAAGtB,iBAAA;EAEzD,MAAM2B,qBAAA,GAAwBlB,MAAA,CAAOmB,MAAM,IAAIH,MAAA,CAAOI,IAAI,CAACpB,MAAA,CAAOmB,MAAM,EAAEE,MAAM,GAAG;EACnF,MAAM;IAAEC,KAAA,GAAQ;IAAIC,MAAA,GAAS;IAAGC,IAAA;IAAMvB,UAAA;IAAYwB,SAAA,GAAY;IAAGC;EAAU,CAAE,GAAG1B,MAAA;EAChF,MAAM2B,WAAA,GAAc3B,MAAA,CAAO4B,SAAS,KAAK,IAAI;EAE7C,MAAM;IAAE/B,KAAA;IAAOgC;EAAI,CAAE,GAAGjB,KAAA,CAAMkB,IAAI;EAClC,MAAM5B,MAAA,GAAS,MAAMU,KAAA,CAAMhB,SAAS,CAACmC,QAAQ,CAACP,IAAA,aAAAA,IAAA,cAAAA,IAAA,GAAQ,IAAIzB,QAAA;EAE1D;EACA,IAAIiC,kBAAA,GAAqBpB,KAAA,CAAMqB,MAAM,CAAC,qBAAqB;EAC3D,IAAI,CAACD,kBAAA,EAAoB;IACvB,MAAME,2BAAA,GAA8B,MAAMtB,KAAA,CAAMf,KAAK,CAACsC,gCAAgC,CAACtC,KAAA;IAEvFmC,kBAAA,GAAqB,MAAMpB,KAAA,CAAMf,KAAK,CAACuC,uBAAuB,CAACvC,KAAA;IAC/DmC,kBAAA,GAAqBA,kBAAA,CAAmBK,MAAM,CAAE9B,IAAA,IAC9C2B,2BAA2B,CAAC3B,IAAA,CAAK,CAAC+B,UAAU,CAAC;IAG/C1B,KAAA,CAAMqB,MAAM,CAAC,qBAAqB,GAAGD,kBAAA;EACvC;EAEA,IAAI/B,UAAA,IAAcA,UAAA,KAAe,KAAK;IACpC,KAAK,MAAMM,IAAA,IAAQN,UAAA,EAAY;MAC7B,IAAI,CAAC+B,kBAAA,CAAmBO,QAAQ,CAAChC,IAAA,GAAiB;QAChD,MAAMrB,WAAA,CAAY,iBAAiBqB,IAAA,EAAgByB,kBAAA,CAAmBQ,IAAI,CAAC;MAC7E;IACF;IAEAR,kBAAA,GAAqBA,kBAAA,CAAmBK,MAAM,CAAE9B,IAAA,IAAiBN,UAAC,CAAwBsC,QAAQ,CAAChC,IAAA;EACrG;EAEA;EACA,MAAMkC,OAAA,GAAU,MAAM9C,mBAAA,CACpBiB,KAAA,CAAMhB,SAAS,EACfgB,KAAA,CAAMf,KAAK,EACXe,KAAA,CAAMd,cAAc,EACpBC,QAAA,EACAC,MAAA,EACAgC,kBAAA,EACA9B,MAAA,EACA,MAAMU,KAAA,CAAMd,cAAc,CAAC4C,KAAK,CAACb,IAAA,GACjCzB,SAAA;EAGF;EACA,MAAMuC,UAAA,GAAa3B,MAAA,CAAOI,IAAI,EAAAN,aAAA,GAACd,MAAA,CAAO4C,KAAK,cAAA9B,aAAA,cAAAA,aAAA,GAAI,CAAC,GAAGO,MAAM,GAAG;EAC5D,IAAIwB,eAAA,GAAwC,EAAE;EAE9C,IAAIF,UAAA,EAAY;IACdE,eAAA,GAAkB,MAAMjC,KAAA,CAAMf,KAAK,CAACiD,mBAAmB,CAACL,OAAA,EAAS5C,KAAA,EAAOG,MAAA,CAAO4C,KAAK;EACtF;EAEA,MAAMG,YAAA,GAAe7C,MAAA,CAAOmB,MAAM;EAElC,IAAI0B,YAAA,IAAiB9C,UAAA,IAAcA,UAAA,CAAWoB,MAAM,GAAG,GAAI;IACzD;IACA,MAAM2B,aAAA,GAAgBhB,kBAAA,CAAmBX,MAAM;IAC/C,KAAK,IAAI4B,CAAA,GAAI,GAAGA,CAAA,GAAID,aAAA,EAAeC,CAAA,IAAK;MAAA,IAAAC,IAAA;UAoBuBC,aAAA;MAnB7D,MAAM5C,IAAA,GAAOyB,kBAAkB,CAACiB,CAAA,CAAE;MAElC,IAAIF,YAAA,KAAiB,GAAG;QACtB,KAAK,IAAIK,CAAA,GAAI,GAAGA,CAAA,GAAIL,YAAA,EAAcK,CAAA,IAAK;UACrC,MAAM5B,IAAA,GAAOtB,MAAM,CAACkD,CAAA,CAAE;UAEtB;UACA,MAAMC,SAAA,GAAY,MAAMzC,KAAA,CAAMf,KAAK,CAACc,MAAM,CAAC8B,OAAA,EAAS5C,KAAA,EAAOU,IAAA,EAAMiB,IAAA;UAEjElC,aAAA,CAAcmD,OAAA,CAAQpC,QAAQ,CAACE,IAAA,CAAK,CAACiB,IAAA,CAAK,EAAE6B,SAAA;QAC9C;MACF,OAAO;QACLZ,OAAA,CAAQpC,QAAQ,CAACE,IAAA,CAAK,CAAC,GAAG,GAAG,EAAE;QAC/B,MAAM8C,SAAA,GAAY,MAAMzC,KAAA,CAAMf,KAAK,CAACc,MAAM,CAAC8B,OAAA,EAAS5C,KAAA,EAAOU,IAAA,EAAM;QACjEjB,aAAA,CAAcmD,OAAA,CAAQpC,QAAQ,CAACE,IAAA,CAAK,CAAC,GAAG,EAAE8C,SAAA;MAC5C;MAEA,MAAMC,MAAA,GAASb,OAAA,CAAQpC,QAAQ,CAACE,IAAA,CAAK;MACrC,MAAMgD,IAAA,GAAOvC,MAAA,CAAOwC,MAAM,CAACF,MAAA;MAC3Bb,OAAA,CAAQnC,gBAAgB,CAACC,IAAA,CAAK,GAAG5B,qBAAA,CAAsB4E,IAAA,GAAAL,IAAA,GAAMlD,MAAA,aAAAA,MAAA,wBAAAmD,aAAA,GAAAnD,MAAA,CAAQyD,KAAK,cAAbN,aAAA,uBAAAA,aAAe,CAAC5C,IAAA,CAAK,cAAA2C,IAAA,cAAAA,IAAA,GAAI,GAAGzB,SAAA,EAAWsB,YAAA;MACpG,MAAMW,UAAA,GAAajB,OAAA,CAAQnC,gBAAgB,CAACC,IAAA,CAAK;MAEjD,MAAMoD,gBAAA,GAAmBD,UAAA,CAAWrC,MAAM;MAC1C,KAAK,IAAI4B,CAAA,GAAI,GAAGA,CAAA,GAAIU,gBAAA,EAAkBV,CAAA,IAAK;QACzC,MAAM,CAACW,EAAA,EAAIC,KAAA,CAAM,GAAGH,UAAU,CAACT,CAAA,CAAE;QACjC,MAAMa,SAAA,GAAYrB,OAAA,CAAQ/B,aAAa,CAACkD,EAAA,CAAG;QAC3C,IAAIE,SAAA,EAAW;UACbrB,OAAA,CAAQ/B,aAAa,CAACkD,EAAA,CAAG,GAAGE,SAAA,GAAYD,KAAA,GAAQ;QAClD,OAAO;UACLpB,OAAA,CAAQ/B,aAAa,CAACkD,EAAA,CAAG,GAAGC,KAAA;QAC9B;MACF;IACF;EACF,OAAO,IAAI3D,MAAA,CAAOmB,MAAM,KAAK,KAAKG,IAAA,EAAM;IACtC;IACA;IACA;IACAiB,OAAA,CAAQ/B,aAAa,GAAG,CAAC;EAC3B,OAAO;IACL+B,OAAA,CAAQ/B,aAAa,GAAGM,MAAA,CAAO+C,WAAW,CACxC/C,MAAA,CAAOI,IAAI,CAAC,MAAMR,KAAA,CAAMd,cAAc,CAACkE,MAAM,CAACpD,KAAA,CAAMkB,IAAI,CAACD,IAAI,GAAGoC,GAAG,CAACzE,CAAA,IAAK,CAACA,CAAA,EAAG,EAAE;EAEnF;EAEA;EACA,IAAI0E,eAAA,GAAkBlD,MAAA,CAAOmD,OAAO,CAAC1B,OAAA,CAAQ/B,aAAa,EAAEuD,GAAG,CAACG,KAAA;IAAA,IAAC,CAACR,EAAA,EAAIC,KAAA,CAAM,GAAAO,KAAA;IAAA,OAAK,CAAC,CAACR,EAAA,EAAIC,KAAA,CAAM;EAAA;EAE7F;EACA,IAAIlB,UAAA,EAAY;IACduB,eAAA,GAAkBrF,oBAAA,CAAqBgE,eAAA,EAAiBqB,eAAA;EAC1D;EAEA,IAAIlE,MAAA,CAAOqE,MAAM,EAAE;IACjB,IAAI,OAAOrE,MAAA,CAAOqE,MAAM,KAAK,YAAY;MACvC,MAAMC,GAAA,GAAMJ,eAAA,CAAgBD,GAAG,CAACM,KAAA;QAAA,IAAC,CAACX,EAAA,CAAG,GAAAW,KAAA;QAAA,OAAKX,EAAA;MAAA;MAC1C,MAAM/B,IAAA,GAAO,MAAMjB,KAAA,CAAMd,cAAc,CAAC0E,WAAW,CAAC5D,KAAA,CAAMkB,IAAI,CAACD,IAAI,EAAEyC,GAAA;MACrE,MAAMG,kBAAA,GAAiE5C,IAAA,CAAKoC,GAAG,CAAC,CAACvE,CAAA,EAAGuD,CAAA,KAAM,CACxFiB,eAAe,CAACjB,CAAA,CAAE,CAAC,EAAE,EACrBiB,eAAe,CAACjB,CAAA,CAAE,CAAC,EAAE,EACrBvD,CAAA,CACD;MACD+E,kBAAA,CAAmBC,IAAI,CAAC1E,MAAA,CAAOqE,MAAM;MACrCH,eAAA,GAAkBO,kBAAA,CAAmBR,GAAG,CAACU,KAAA;QAAA,IAAC,CAACf,EAAA,EAAIC,KAAA,CAAM,GAAAc,KAAA;QAAA,OAAK,CAACf,EAAA,EAAIC,KAAA,CAAM;MAAA;IACvE,OAAO;MACLK,eAAA,GAAkB,MAAMtD,KAAA,CAAMgE,MAAM,CACjCP,MAAM,CAACzD,KAAA,CAAMkB,IAAI,CAAC+C,OAAO,EAAEX,eAAA,EAAiBlE,MAAA,CAAOqE,MAAM,EACzDS,IAAI,CAACC,OAAA,IACJA,OAAA,CAAQd,GAAG,CAACe,KAAA;QAAA,IAAC,CAACpB,EAAA,EAAIC,KAAA,CAAM,GAAAmB,KAAA;QAAA,OAAK,CAAC/F,qBAAA,CAAsB2B,KAAA,CAAMqE,uBAAuB,EAAErB,EAAA,GAAKC,KAAA,CAAM;MAAA;IAEpG;EACF,OAAO;IACLK,eAAA,GAAkBA,eAAA,CAAgBQ,IAAI,CAACrF,uBAAA;EACzC;EAEA,IAAI0F,OAAA;EACJ,IAAI,CAACpD,WAAA,IAAeD,UAAA,EAAY;IAC9BqD,OAAA,GAAU,MAAMG,0BAAA,CAA2BtE,KAAA,EAAOsD,eAAA,EAAiB3C,MAAA,EAAQD,KAAA,EAAOI,UAAA;EACpF,OAAO,IAAI,CAACC,WAAA,EAAa;IACvBoD,OAAA,GAAU,MAAMI,cAAA,CAAevE,KAAA,EAAOsD,eAAA,EAAiB3C,MAAA,EAAQD,KAAA;EACjE;EAEA,MAAM8D,YAAA,GAAwC;IAC5CC,OAAA,EAAS;MACPC,SAAA,EAAW;MACXC,GAAA,EAAK;IACP;IACA;IACAC,IAAA,EAAM,EAAE;IACR9C,KAAA,EAAOwB,eAAA,CAAgB7C;EACzB;EAEA,IAAI,OAAO0D,OAAA,KAAY,aAAa;IAClCK,YAAA,CAAaI,IAAI,GAAGT,OAAA,CAAQ1C,MAAM,CAACoD,OAAA;EACrC;EAEA,IAAIvE,qBAAA,EAAuB;IACzB;IACA,MAAMC,MAAA,GAAS,MAAMvC,SAAA,CAAUgC,KAAA,EAAOsD,eAAA,EAAiBlE,MAAA,CAAOmB,MAAM;IACpEiE,YAAA,CAAajE,MAAM,GAAGA,MAAA;EACxB;EAEA,IAAInB,MAAA,CAAO0F,OAAO,EAAE;IAClBN,YAAA,CAAaO,MAAM,GAAG,MAAM7G,SAAA,CAA6B8B,KAAA,EAAOsD,eAAA,EAAiBlE,MAAA,CAAO0F,OAAO;EACjG;EAEA,IAAI9E,KAAA,CAAMgF,WAAW,EAAE;IACrB,MAAM7G,cAAA,CAAe6B,KAAA,CAAMgF,WAAW,EAAEhF,KAAA,EAAOZ,MAAA,EAAQD,QAAA,EAAUqF,YAAA;EACnE;EAEA;EACAA,YAAA,CAAaC,OAAO,GAAI,MAAMzE,KAAA,CAAMiF,iBAAiB,CACnD,OAAO1G,kBAAA,MAAwBsD,OAAA,CAAQrC,SAAS;EAGlD,OAAOgF,YAAA;AACT;AAEA,eAAeF,2BACbtE,KAAQ,EACRsD,eAA+C,EAC/C3C,MAAc,EACdD,KAAa,EACbI,UAAqC,EACF;EACnC,MAAMG,IAAA,GAAOjB,KAAA,CAAMkB,IAAI,CAACD,IAAI;EAE5B;EACA,MAAM2B,MAAA,GAAS,IAAIsC,GAAA;EAEnB;EACA;EACA,MAAMf,OAAA,GAAoC,EAAE;EAE5C,MAAMgB,SAAA,GAAqC,IAAIC,GAAA;EAC/C,MAAMC,qBAAA,GAAwB/B,eAAA,CAAgB7C,MAAM;EACpD,IAAIqB,KAAA,GAAQ;EACZ,KAAK,IAAIO,CAAA,GAAI,GAAGA,CAAA,GAAIgD,qBAAA,EAAuBhD,CAAA,IAAK;IAC9C,MAAMiD,UAAA,GAAahC,eAAe,CAACjB,CAAA,CAAE;IAErC;IACA,IAAI,OAAOiD,UAAA,KAAe,aAAa;MACrC;IACF;IAEA,MAAM,CAACtC,EAAA,EAAIC,KAAA,CAAM,GAAGqC,UAAA;IAEpB,IAAIH,SAAA,CAAUI,GAAG,CAACvC,EAAA,GAAK;MACrB;IACF;IAEA,MAAMwC,GAAA,GAAM,MAAMxF,KAAA,CAAMd,cAAc,CAACuG,GAAG,CAACxE,IAAA,EAAM+B,EAAA;IACjD,MAAM0C,KAAA,GAAQ,MAAMlH,SAAA,CAAUgH,GAAA,EAAe1E,UAAA;IAC7C,IAAI,OAAO4E,KAAA,KAAU,eAAe9C,MAAA,CAAO2C,GAAG,CAACG,KAAA,GAAQ;MACrD;IACF;IACA9C,MAAA,CAAO+C,GAAG,CAACD,KAAA,EAAO,IAAI;IAEtB5D,KAAA;IACA;IACA,IAAIA,KAAA,IAASnB,MAAA,EAAQ;MACnB;IACF;IAEAwD,OAAA,CAAQyB,IAAI,CAAC;MAAE5C,EAAA,EAAI5E,2BAAA,CAA4B4B,KAAA,CAAMqE,uBAAuB,EAAErB,EAAA;MAAKC,KAAA;MAAO4C,QAAA,EAAUL;IAAK;IACzGL,SAAA,CAAUW,GAAG,CAAC9C,EAAA;IAEd;IACA,IAAIlB,KAAA,IAASnB,MAAA,GAASD,KAAA,EAAO;MAC3B;IACF;EACF;EAEA,OAAOyD,OAAA;AACT;AAEA,eAAeI,eACbvE,KAAQ,EACRsD,eAA+C,EAC/C3C,MAAc,EACdD,KAAa,EACsB;EACnC,MAAMO,IAAA,GAAOjB,KAAA,CAAMkB,IAAI,CAACD,IAAI;EAE5B,MAAMkD,OAAA,GAAoC4B,KAAA,CAAMC,IAAI,CAAC;IACnDvF,MAAA,EAAQC;EACV;EAEA,MAAMyE,SAAA,GAAqC,IAAIC,GAAA;EAE/C;EACA;EACA;EACA,KAAK,IAAI/C,CAAA,GAAI1B,MAAA,EAAQ0B,CAAA,GAAI3B,KAAA,GAAQC,MAAA,EAAQ0B,CAAA,IAAK;IAC5C,MAAMiD,UAAA,GAAahC,eAAe,CAACjB,CAAA,CAAE;IAErC;IACA,IAAI,OAAOiD,UAAA,KAAe,aAAa;MACrC;IACF;IAEA,MAAM,CAACtC,EAAA,EAAIC,KAAA,CAAM,GAAGqC,UAAA;IAEpB,IAAI,CAACH,SAAA,CAAUI,GAAG,CAACvC,EAAA,GAAK;MACtB;MACA;MACA,MAAMiD,OAAA,GAAU,MAAMjG,KAAA,CAAMd,cAAc,CAACuG,GAAG,CAACxE,IAAA,EAAM+B,EAAA;MACrDmB,OAAO,CAAC9B,CAAA,CAAE,GAAG;QAAEW,EAAA,EAAI5E,2BAAA,CAA4B4B,KAAA,CAAMqE,uBAAuB,EAAErB,EAAA;QAAKC,KAAA;QAAO4C,QAAA,EAAUI;MAAS;MAC7Gd,SAAA,CAAUW,GAAG,CAAC9C,EAAA;IAChB;EACF;EACA,OAAOmB,OAAA;AACT"},"metadata":{},"sourceType":"module","externalDependencies":[]}